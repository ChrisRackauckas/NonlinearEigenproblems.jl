{
    "docs": [
        {
            "location": "/",
            "text": "NEP-PACK\n\n\nNEP-PACK is a package with implementations of methods to solve nonlinear eigenvalue problems of the type: Find $(\u03bb,v)\\in\\mathbb{C}\\times\\mathbb{C}^n$ such that\n\n\n$$\nM(\u03bb)v=0\n$$\n\n\nand $v\\neq 0$.\n\n\n\n\nGetting started\n\n\nInstall it as an unregistered package in Julia's REPL package mode by writing \n] add git:/..\n:\n\n\njulia> ]\n(v1.0) pkg> add git://github.com/nep-pack/NonlinearEigenproblems.jl.git\n\n\n\n\n\nThen we can start to load the NEP-PACK package\n\n\njulia> using NonlinearEigenproblems\n\n\n\n\nAs a first example we will solve the NEP associated with the matrix polynomial\n\n\n$$\nM(\u03bb)=\\begin{bmatrix}1&3\\newline5&6\\end{bmatrix}+\n\u03bb\\begin{bmatrix}3&4\\newline6&6\\end{bmatrix}+\n\u03bb^2\\begin{bmatrix}1&0\\newline0&1\\end{bmatrix}\n$$\n\n\nThe following code creates this NEP, by constructing an object called \nPEP\n, an abbreviation for polynomial eigenvalue problem. Here we solve it using the NEP solution method implemented in \npolyeig()\n:\n\n\njulia> A0=[1.0 3; 5 6]; A1=[3.0 4; 6 6]; A2=[1.0 0; 0 1.0];\njulia> nep=PEP([A0,A1,A2])\nPEP(2, Array{Float64,2}[[1.0 3.0; 5.0 6.0], [3.0 4.0; 6.0 6.0], [1.0 0.0; 0.0 1.0]])\njulia> \u03bb,v=polyeig(nep)\n(Complex{Float64}[1.36267+0.0im, -0.824084+0.280682im, -0.824084-0.280682im, -8.7145+0.0im], Complex{Float64}[-1.0+0.0im 0.739183-0.196401im 0.739183+0.196401im 0.627138+0.0im; 0.821812+0.0im -0.501408-0.375337im -0.501408+0.375337im 1.0+0.0im])\n\n\n\n\nYou have now solved your first nonlinear eigenvalue problem with NEP-PACK.\n\n\nIn order to verify that we have a solution, we can check that  $M(\u03bb)$ is singular, with a singular vector $v$ such that $M(\u03bb)v=0$:\n\n\njulia> \u03bb1=\u03bb[1]; v1=v[:,1];\njulia> using LinearAlgebra # the norm-function is in this Julia package\njulia> norm(A0*v1+\u03bb1*A1*v1+\u03bb1^2*v1)/norm(v1)\n1.1502634749464687e-14\n\n\n\n\n\n\nAccessing more complicated applications\n\n\nWe have made benchmark examples available in through the function \nnep_gallery\n:\n\n\njulia> nep=nep_gallery(\"dep0\",100);\njulia> size(nep)\n(100, 100)\njulia> \u03bb,v=mslp(nep,tol=1e-10);\njulia> \u03bb\n0.23169217667341738 - 2.1866254654451488e-16im\njulia> size(v)\n(100,)\njulia> resnorm=norm(compute_Mlincomb(nep,\u03bb,v))\n3.124042808475689e-14\n\n\n\n\nInformation about the gallery can be found by typing \n?nep_gallery\n. The second arument in the call to \nnep_gallery\n is a problem parameter, in this case specifying that the  size of the problem should be \n100\n. The example solves the problem with the NEP-algorithm \nMSLP\n. The parameter \ntol\n specifies the tolerance for iteration termination. Type \n?mslp\n for more information about this NEP-algorithm.\n\n\n\n\nA model of a neuron\n\n\nThe following (delay) differential equation models a neuron\n\n\n$$\n\\dot{x}_1(t)=-\\kappa x_1(t)+\\beta\\tanh(x_1(t-\\tau_3))+a_1\\tanh(x_2(t-\\tau_2))\n$$\n\n\n$$\n\\dot{x}_2(t)=-\\kappa x_2(t)+\\beta\\tanh(x_2(t-\\tau_3))+a_2\\tanh(x_1(t-\\tau_1))\n$$\n\n\nSee \nL. P. Shayer and S. A. Campbell.  Stability, bifurcation and multistability in a system of two coupled neurons with multiple time delays. SIAM J. Applied Mathematics , 61(2):673\u2013700, 2000\n. It is also available as a first demo in \nDDE-BIFTOOL\n. The linear stability analysis of this problem requires the solution of a nonlinear eigenvalue eigenvalue problem\n\n\n$$\nM(\u03bb)=-\u03bbI+A_0+A_1e^{-\\tau_1\u03bb}+A_2e^{-\\tau_2\u03bb}+A_3e^{-\\tau_3\u03bb}\n$$\n\n\nwhere the matrices are the Jacobian at the stationary solution. For the zero stationary solution, the matrices are\n\n\nkappa=0.5; a2=2.34; a1=1; beta=-1;\nA0=-kappa*[1 0; 0 1];\nA1=a2*[0 0; 1 0];\nA2=a1*[0 1; 0 0];\nA3=beta*[1 0; 0 1];\n\n\n\n\nWe can now create the nonlinear eigenvalue problem and compute the stability by first creating the problem\n\n\njulia> tauv=[0;0.2;0.2;1.5];\njulia> dep=DEP([A0, A1,   A2, A3],tauv);\n\n\n\n\nThe constructor  \nDEP\n is an abbreviation for a delay eigenvalue problem, which a  NEP with exponential terms stemming from the stability analysis of a delay-differential equation. See \ntypes\n for other NEP-types. You can now solve this NEP, for instance, with the \ninfinite Arnoldi method\n:\n\n\njulia> \u03bb,V=iar_chebyshev(dep,maxit=100); # This takes some time the first time is run due to JIT-compiler\n\n\n\n\nThe figure in a demo of DDE-BIFTOOL \nhttp://ddebiftool.sourceforge.net/demos/neuron/html/demo1_stst.html\n can be directly generated by\n\n\njulia> using PyPlot;\njulia> plot(real(\u03bb),imag(\u03bb),\"*\")\n\n\n\n\nThis problem is also available in the \nGallery\n by calling \ndep=nep_gallery(\"neuron0\")\n.\n\n\n\n\nThe \"gun\" benchmark problem\n\n\nOne of the most common benchmark problems for NEPs is the so-called \"gun\"-problem. It models an electromagnetic cavity, and it is directly available in the \nGallery\n. (See \n?nep_gallery\n for references.) This is how you can solve it with the \nblock Newton method\n:\n\n\njulia> nep=nep_gallery(\"nlevp_native_gun\");\njulia> n=size(nep,1)\njulia> S=150^2*[1.0 0; 0 1]; V=[[1 0; 0 1]; zeros(n-2,2)];\njulia> (Z,X)=blocknewton(nep,S=S,X=V,displaylevel=1,armijo_factor=0.5,maxit=20)\nIteration 1: Error: 6.081316e+03\nIteration 2: Error: 1.701970e-02 Armijo scaling=0.031250\nIteration 3: Error: 1.814887e-02 Armijo scaling=0.250000\n...\nIteration 13: Error: 6.257442e-09\nIteration 14: Error: 2.525942e-15\n\n\n\n\nThis algorithm returns a partial Schur factorization of the NEP, and therefore the eigenvalues of the small matrix \nZ\n are eigenvalues of the problem. An eigenpair of the NEP can be extracted by diagonalizing:\n\n\njulia> using LinearAlgebra\njulia> (\u039b,P)=eigen(Z);\njulia> VV=X*P;  # Construct the eigenvector matrix\njulia> v=VV[:,1]; \u03bb=\u039b[1]\n61330.208714730004 + 63185.15983933589im\njulia> norm(compute_Mlincomb(nep,\u03bb,v)) # Very small residual\n1.8270553408452648e-16\n\n\n\n\n\n\nWhat now?\n\n\nNow you are ready to have a look at the examples in \nNEP methods\n and  \nNEP Gallery\n.",
            "title": "Introduction"
        },
        {
            "location": "/#nep-pack",
            "text": "NEP-PACK is a package with implementations of methods to solve nonlinear eigenvalue problems of the type: Find $(\u03bb,v)\\in\\mathbb{C}\\times\\mathbb{C}^n$ such that  $$\nM(\u03bb)v=0\n$$  and $v\\neq 0$.",
            "title": "NEP-PACK"
        },
        {
            "location": "/#getting-started",
            "text": "Install it as an unregistered package in Julia's REPL package mode by writing  ] add git:/.. :  julia> ]\n(v1.0) pkg> add git://github.com/nep-pack/NonlinearEigenproblems.jl.git  Then we can start to load the NEP-PACK package  julia> using NonlinearEigenproblems  As a first example we will solve the NEP associated with the matrix polynomial  $$\nM(\u03bb)=\\begin{bmatrix}1&3\\newline5&6\\end{bmatrix}+\n\u03bb\\begin{bmatrix}3&4\\newline6&6\\end{bmatrix}+\n\u03bb^2\\begin{bmatrix}1&0\\newline0&1\\end{bmatrix}\n$$  The following code creates this NEP, by constructing an object called  PEP , an abbreviation for polynomial eigenvalue problem. Here we solve it using the NEP solution method implemented in  polyeig() :  julia> A0=[1.0 3; 5 6]; A1=[3.0 4; 6 6]; A2=[1.0 0; 0 1.0];\njulia> nep=PEP([A0,A1,A2])\nPEP(2, Array{Float64,2}[[1.0 3.0; 5.0 6.0], [3.0 4.0; 6.0 6.0], [1.0 0.0; 0.0 1.0]])\njulia> \u03bb,v=polyeig(nep)\n(Complex{Float64}[1.36267+0.0im, -0.824084+0.280682im, -0.824084-0.280682im, -8.7145+0.0im], Complex{Float64}[-1.0+0.0im 0.739183-0.196401im 0.739183+0.196401im 0.627138+0.0im; 0.821812+0.0im -0.501408-0.375337im -0.501408+0.375337im 1.0+0.0im])  You have now solved your first nonlinear eigenvalue problem with NEP-PACK.  In order to verify that we have a solution, we can check that  $M(\u03bb)$ is singular, with a singular vector $v$ such that $M(\u03bb)v=0$:  julia> \u03bb1=\u03bb[1]; v1=v[:,1];\njulia> using LinearAlgebra # the norm-function is in this Julia package\njulia> norm(A0*v1+\u03bb1*A1*v1+\u03bb1^2*v1)/norm(v1)\n1.1502634749464687e-14",
            "title": "Getting started"
        },
        {
            "location": "/#accessing-more-complicated-applications",
            "text": "We have made benchmark examples available in through the function  nep_gallery :  julia> nep=nep_gallery(\"dep0\",100);\njulia> size(nep)\n(100, 100)\njulia> \u03bb,v=mslp(nep,tol=1e-10);\njulia> \u03bb\n0.23169217667341738 - 2.1866254654451488e-16im\njulia> size(v)\n(100,)\njulia> resnorm=norm(compute_Mlincomb(nep,\u03bb,v))\n3.124042808475689e-14  Information about the gallery can be found by typing  ?nep_gallery . The second arument in the call to  nep_gallery  is a problem parameter, in this case specifying that the  size of the problem should be  100 . The example solves the problem with the NEP-algorithm  MSLP . The parameter  tol  specifies the tolerance for iteration termination. Type  ?mslp  for more information about this NEP-algorithm.",
            "title": "Accessing more complicated applications"
        },
        {
            "location": "/#a-model-of-a-neuron",
            "text": "The following (delay) differential equation models a neuron  $$\n\\dot{x}_1(t)=-\\kappa x_1(t)+\\beta\\tanh(x_1(t-\\tau_3))+a_1\\tanh(x_2(t-\\tau_2))\n$$  $$\n\\dot{x}_2(t)=-\\kappa x_2(t)+\\beta\\tanh(x_2(t-\\tau_3))+a_2\\tanh(x_1(t-\\tau_1))\n$$  See  L. P. Shayer and S. A. Campbell.  Stability, bifurcation and multistability in a system of two coupled neurons with multiple time delays. SIAM J. Applied Mathematics , 61(2):673\u2013700, 2000 . It is also available as a first demo in  DDE-BIFTOOL . The linear stability analysis of this problem requires the solution of a nonlinear eigenvalue eigenvalue problem  $$\nM(\u03bb)=-\u03bbI+A_0+A_1e^{-\\tau_1\u03bb}+A_2e^{-\\tau_2\u03bb}+A_3e^{-\\tau_3\u03bb}\n$$  where the matrices are the Jacobian at the stationary solution. For the zero stationary solution, the matrices are  kappa=0.5; a2=2.34; a1=1; beta=-1;\nA0=-kappa*[1 0; 0 1];\nA1=a2*[0 0; 1 0];\nA2=a1*[0 1; 0 0];\nA3=beta*[1 0; 0 1];  We can now create the nonlinear eigenvalue problem and compute the stability by first creating the problem  julia> tauv=[0;0.2;0.2;1.5];\njulia> dep=DEP([A0, A1,   A2, A3],tauv);  The constructor   DEP  is an abbreviation for a delay eigenvalue problem, which a  NEP with exponential terms stemming from the stability analysis of a delay-differential equation. See  types  for other NEP-types. You can now solve this NEP, for instance, with the  infinite Arnoldi method :  julia> \u03bb,V=iar_chebyshev(dep,maxit=100); # This takes some time the first time is run due to JIT-compiler  The figure in a demo of DDE-BIFTOOL  http://ddebiftool.sourceforge.net/demos/neuron/html/demo1_stst.html  can be directly generated by  julia> using PyPlot;\njulia> plot(real(\u03bb),imag(\u03bb),\"*\")  This problem is also available in the  Gallery  by calling  dep=nep_gallery(\"neuron0\") .",
            "title": "A model of a neuron"
        },
        {
            "location": "/#the-gun-benchmark-problem",
            "text": "One of the most common benchmark problems for NEPs is the so-called \"gun\"-problem. It models an electromagnetic cavity, and it is directly available in the  Gallery . (See  ?nep_gallery  for references.) This is how you can solve it with the  block Newton method :  julia> nep=nep_gallery(\"nlevp_native_gun\");\njulia> n=size(nep,1)\njulia> S=150^2*[1.0 0; 0 1]; V=[[1 0; 0 1]; zeros(n-2,2)];\njulia> (Z,X)=blocknewton(nep,S=S,X=V,displaylevel=1,armijo_factor=0.5,maxit=20)\nIteration 1: Error: 6.081316e+03\nIteration 2: Error: 1.701970e-02 Armijo scaling=0.031250\nIteration 3: Error: 1.814887e-02 Armijo scaling=0.250000\n...\nIteration 13: Error: 6.257442e-09\nIteration 14: Error: 2.525942e-15  This algorithm returns a partial Schur factorization of the NEP, and therefore the eigenvalues of the small matrix  Z  are eigenvalues of the problem. An eigenpair of the NEP can be extracted by diagonalizing:  julia> using LinearAlgebra\njulia> (\u039b,P)=eigen(Z);\njulia> VV=X*P;  # Construct the eigenvector matrix\njulia> v=VV[:,1]; \u03bb=\u039b[1]\n61330.208714730004 + 63185.15983933589im\njulia> norm(compute_Mlincomb(nep,\u03bb,v)) # Very small residual\n1.8270553408452648e-16",
            "title": "The \"gun\" benchmark problem"
        },
        {
            "location": "/#what-now",
            "text": "Now you are ready to have a look at the examples in  NEP methods  and   NEP Gallery .",
            "title": "What now?"
        },
        {
            "location": "/methods/",
            "text": "NEP Methods\n\n\nThe NEP solver methods implemented in NEP-PACK, are accessed by the functions below. The functions all return $\u03bb,v,w$ where $\u03bb$ is either a number (eigenvalue) a vector of eigenvalues $v$ is either a vector containing an eigenvector or a matrix whose columns corresponding to the eigenvectors.\n\n\nThe first parameter optional parameter in all NEP solver methods is a type. This type specifies which arithmetic should be used for the algorithm.\n\n\nExample:\n\n\njulia> nep=nep_gallery(\"dep0\")\njulia> \u03bb,v=augnewton(Complex128,nep,v=ones(5))\n(0.8347353572199425 + 0.0im, Complex{Float64}[0.480386+0.0im, 0.0631636+0.0im, -0.136405+0.0im, 0.214274+0.0im, 0.378581+0.0im])\njulia> typeof(\u03bb)\nComplex{Float64}\njulia> \u03bb,v=augnewton(Float16,nep,v=ones(5))\n(Float16(0.8223), Float16[0.47388, 0.063904, -0.13843, 0.21692, 0.38306])\njulia> typeof(\u03bb)\nFloat16\n\n\n\n\n\n\nNewton type methods\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.newton\n \u2014 \nFunction\n.\n\n\n\u03bb,v = newton([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel,][armijo_factor=1,][armijo_max])\n\n\n\n\nApplies Newton-Raphsons method on the system of nonlinear equations with \nn+1\n unknowns:\n\n\n$$\nM(\u03bb)v=0\n$$\n\n\n$$\nc^Hv-1=0\n$$\n\n\nThe kwarg \nerrmeasure\n is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). The iteration is continued until \nerrmeasure\n is less than \ntol\n. \n\u03bb\n and \nv\n are starting approximations. \nc\n is the orthogonalization vector.  If \nc=0\n the current approximation will be used for the orthogonalization. \narmijo_factor\n specifies if an Armijo rule should be applied, and its value specifies the scaling factor of the step length (per reduction step). The variable \narmijo_max\n specifies the maximum number of step length reductions.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> \u03bb,v=newton(nep);\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n1.6066157878930876e-16\n\n\n\n\nReferences\n\n\n\n\nNichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.\n\n\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.augnewton\n \u2014 \nFunction\n.\n\n\naugnewton([eltype], nep::NEP; [errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel,][linsolvercreator,][armijo_factor,][armijo_max])\n\n\n\n\nRun the augmented Newton method. The method is equivalent to \nnewton()\n in exact arithmetic,  but works only with operations on vectors of length \nn\n. The \nlinsolvecreator\n is used to initiate linear solvers. See \nnewton()\n for other parameters.\n\n\nExample\n\n\nThis illustrates the equivalence between \nnewton\n and \naugnewton\n.\n\n\njulia> nep=nep_gallery(\"dep1\")\njulia> \u03bb1,v1=newton(nep,maxit=20,v=ones(size(nep,1)),\u03bb=0)\njulia> \u03bb2,v2=augnewton(nep,maxit=20,v=ones(size(nep,1)),\u03bb=0)\njulia> \u03bb1-\u03bb2\n0.0 + 0.0im\n\n\n\n\nReferences\n\n\n\n\nNichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.\n\n\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.resinv\n \u2014 \nFunction\n.\n\n\n\u03bb,v = resinv([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel,][armijo_factor=1,][armijo_max,][linsolvecreator])\n\n\n\n\nApplies residual inverse iteration method for nonlinear eigenvalue problems. The kwarg \nlinsolvecreator\n is a function which specifies how the linear system is created. The function calls \ncompute_rf\n for the computation of the Rayleigh functional. See \nnewton()\n for other parameters.\n\n\nExample\n\n\nThe example shows how to specify if the method should run in real or complex mode (or any other \nNumber\n type).\n\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> \u03bb,v=resinv(nep,\u03bb=-2,v=ones(size(nep,1)))\njulia> typeof(\u03bb)\nComplex{Float64}\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n1.817030659827106e-14\njulia> \u03bb,v=resinv(Float64,nep,\u03bb=-2,v=ones(size(nep,1)))\njulia> typeof(\u03bb)\nFloat64\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n1.817030659827106e-14\n\n\n\n\nReferences\n\n\n\n\nA. Neumaier, Residual inverse iteration for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 22 (1985) 914-923\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.quasinewton\n \u2014 \nFunction\n.\n\n\nquasinewton([T=ComplexF64],nep,[errmeasure,][tol,][maxit,][\u03bb,][v][ws][displaylevel][linsolvercreator,][armijo_factor,][armijo_max])\n\n\n\n\nAn implementation of the quasi-Newton approach referred to as quasi-Newton 2 in the reference. The method involves one linear system solve per iteration corresponding with the matrix $M(\u03bb)$, where $\u03bb$ is constant. The vector \nws\n is a representation of the normalization, in the sense that $c^T=w_s^TM(\u03bb)$, where all iterates satisfy $c^Tx_i=1$. See \nnewton()\n for other parameters.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"pep0\")\njulia> \u03bb,v=quasinewton(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n6.301479387102376e-15\n\n\n\n\nReferences\n\n\n\n\nJarlebring, Koskela, Mele, Disguised and new Quasi-Newton methods for nonlinear eigenvalue problems, Numer. Algorithms, 79:311-335, 2018. \npreprint\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.mslp\n \u2014 \nFunction\n.\n\n\n mslp([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][displaylevel,][eigsolvertype::DataType][armijo_factor=1,][armijo_max])\n\n\n\n\nRuns the method of successive linear problems. The  method requires the solution of a generalized eigenvalue problem in every iteration. The method used for the eigenvalue computation is specified in eigsolvertype. See \nnewton\n for other parameters.\n\n\nExample\n\n\nCreate a rational NEP with SPMFs.\n\n\njulia> Av=[ones(3,3),eye(3,3),triu(ones(3,3))];\njulia> fv=[S-> S, S -> S^2, S::AbstractArray -> inv(Matrix(S)-eye(S)*10)]\njulia> nep=SPMF_NEP(Av,fv)\njulia> (\u03bb,v)=mslp(nep)\njulia> compute_Mlincomb(nep,\u03bb,v)\n3-element Array{Complex{Float64},1}:\n -1.38778e-17+1.65715e-18im\n -5.55112e-17+1.30633e-17im\n -4.16334e-17-1.54436e-17im\n\n\n\n\nReferences\n\n\n\n\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.rfi\n \u2014 \nFunction\n.\n\n\nrfi(nep,nept,[\u03bb=0,][errmeasure=default_errmeasure,][tol=eps()*100,][maxit=100,][v=randn,][u=randn,][displaylevel=0,][linsolvecreator=default_linsolvecreator,])\n\n\n\n\nThis is an implementation of the two-sided Rayleigh functional Iteration (RFI) to compute an eigentriplet of the problem specified by \nnep\n. This method requires the transpose of the NEP, specified in \nnept\n. \n\u03bb\n, \nu\n and \nv\n are initial guesses for the eigenvalue, the right eigenvector and the left eigenvector respectively. A \nNoConvergenceException\n is thrown if an eigentriplet is not found in \nmaxit\n iterations.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> nept=DEP([nep.A[1]',nep.A[2]'])\njulia> \u03bb,v,u=rfi_b(nep,nept)\njulia> compute_resnorm(nep,\u03bb,v) % v is a right eigenvector\n4.347204570675246e-16\njulia> compute_resnorm(nept,\u03bb,u) % u is a left eigenvector\n7.173081573164097e-16\n\n\n\n\nReference\n\n\n\n\nAlgorithm 4 in  Schreiber, Nonlinear Eigenvalue Problems: Newton-type Methods and Nonlinear Rayleigh Functionals, PhD thesis, TU Berlin, 2008.\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.newtonqr\n \u2014 \nFunction\n.\n\n\n\u03bb,v = newtonqr([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel])\n\n\n\n\nThis function implements the Newton-QR method as formulated in the reference. The method ivolves the computation of a rank-revealing QR factorization of $M(\u03bb)$, with the idea that on convergence the the last diagonal element $R[n,n]$ of the upper-triangular matrix $R$ becomes zero as a result of $M(\u03bb)$ becoming singular. Since the computation of a QR factorization is expensive, it is advisable to use this method for problems of small size or problems with a certain structure that makes the QR computation less expensive. See \nnewton\n for description of the function arguements.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"pep0\")\njulia> \u03bb,v=newtonqr(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n1.0442559980785471e-14\n\n\n\n\nReferences\n\n\n\n\nKublanovskaya, V. N., (1970).  On an approach to the solution of the generalized latent value problem for \u03bb-matrices, SIAM J. Numer. Anal. 7, 532\u2013537\n\n\nG\u00fcttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.implicitdet\n \u2014 \nFunction\n.\n\n\n\u03bb,v = implicitdet([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel])\n\n\n\n\nThis function implements the Implicit determinant method as formulated Algorithm 4.3 in the reference. The method applies Newton-Raphson to the equation $det(M(\u03bb))/det(G(\u03bb)) = 0$, where $G(\u03bb)$ is a saddle point matrix with $M(\u03bb)$ in the (1,1) block. The (2,1) and (1,2) blocks of $G(\u03bb)$ are set to $c^H$ and $c$ respectively. Note that $G(\u03bb)$ can be non-singular even when $M(\u03bb)$ is singular. See reference for more information. See \nnewton\n for description of the function arguements.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"pep0\")\njulia> \u03bb,v=implicitdet(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n3.75723275262885e-14\n\n\n\n\nReferences\n\n\n\n\nSpence, A., & Poulton, C. (2005). Photonic band structure calculations using nonlinear eigenvalue techniques, J. Comput. Phys., 204 (2005), pp. 65\u20138\n\n\nG\u00fcttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.broyden\n \u2014 \nFunction\n.\n\n\nS,V = broyden([eltype,]nep::NEP[,approxnep::NEP];kwargs)\n\n\n\n\nRuns Broydens method (with deflation) for the nonlinear eigenvalue problem defined by nep. An approximate nep can be provided which is used as an initialization of starting matrix/vectors.\n\n\nThe method computes an invariant pair and can therefore find several eigenvalues. The retured value is (S,V) is an invariant pair and the eigenvalues are on the diagonal of S.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> S,V=broyden(nep);\njulia> \u03bb=S[1,1]\n-0.3587189459686267 - 3.0010731412746105e-31im\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n1.6066157878930856e-16\njulia> \u03bb=S[2,2]\n-0.04093521177097334 + 1.486011530941621im\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n4.159109513753696e-16\njulia> \u03bb=S[3,3]\n0.8347353572199486 + 1.5032076225139986e-14im\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n1.296144276122994e-14\njulia> broyden(nep,displaylevel=2,check_error_every=1);  % Prints out a lot more convergence info\n\n\n\n\nReferences\n\n\n\n\nJarlebring, Broyden\u2019s method for nonlinear eigenproblems, 2018, https://arxiv.org/pdf/1802.07322\n\n\n\n\nsource\n\n\n\n\nProjection methods\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.nlar\n \u2014 \nFunction\n.\n\n\nfunction nlar([eltype],nep::ProjectableNEP,[orthmethod=ModifiedGramSchmidt],[neigs=10],[errmeasure=default_errmeasure],[tol=eps(real(T))*100],[maxit=100],[\u03bb0=0],[v0=randn(T,size(nep,1))],[displaylevel=0],[linsolvercreator=default_linsolvercreator],[R=0.01],[eigval_sorter=residual_eigval_sorter],[qrfact_orth=false],[max_subspace=100],[num_restart_ritz_vecs=8],[inner_solver_method=DefaultInnerSolver])\n\n\n\n\nThe function implements the Nonlinear Arnoldi method, which finds \nneigs\n eigenpairs(or throws a \nNoConvergenceException\n) by projecting the problem to a subspace that is expanded in the course  of the algorithm. The basis is orthogonalized either by using the QR method if \nqrfact_orth\n is \ntrue\n or else by an orthogonalization method \northmethod\n). This entails solving a smaller projected problem using a method specified by \ninner_solver_method\n. (\n\u03bb0\n,\nv0\n) is the initial guess for the eigenpair. \nlinsolvercreator\n specifies how the linear system is created and solved. \nR\n is a parameter used by the function specified by \neigval_sorter\n to reject those ritz values that are within a distance \nR\n from any of the converged eigenvalues, so that repeated convergence to the same eigenpair can be avoided. \nmax_subspace\n is the maximum allowable size of the basis befor the algorithm restarts using a basis made of \nnum_restart_ritz_vecs\n ritz vectors and the eigenvectors that the algorithm has converged to.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"dep0_tridiag\");\njulia> \u03bb,v=nlar(nep,tol=1e-5,neigs=1,maxit=50);\njulia> norm(compute_Mlincomb(nep,\u03bb[1],v))\n7.722757003764154e-7\n\n\n\n\nReferences\n\n\n\n\nH. Voss, An Arnoldi method for nonlinear eigenvalue problems. BIT. Numer. Math. 44: 387-401, 2004.\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.jd_betcke\n \u2014 \nFunction\n.\n\n\njd_betcke([eltype]], nep::ProjectableNEP; [Neig=1], [tol=eps(real(T))*100], [maxit=100], [\u03bb=zero(T)], [orthmethod=DGKS],  [errmeasure=default_errmeasure], [linsolvercreator=default_linsolvercreator], [v = randn(size(nep,1))], [displaylevel=0], [inner_solver_method=DefaultInnerSolver], [projtype=:PetrovGalerkin], [target=zero(T)])\n\n\n\n\nThe function computes eigenvalues using Jacobi-Davidson method, which is a projection method. The projected problems are solved using a solver spcified through the type \ninner_solver_method\n. For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by \northmethod\n, see the package \nIterativeSolvers.jl\n. The function tries to compute \nNeig\n number of eigenvalues, and throws a \nNoConvergenceException\n if it cannot. The value \n\u03bb\n and the vector \nv\n are initial guesses for an eigenpair. \nlinsolvercreator\n is a function which specifies how the linear system is created and solved. The \ntarget\n is the center around which eiganvlues are computed. \nerrmeasure\n is a function handle which can be used to specify how the error is measured. By default the method uses a Petrov-Galerkin framework, with a trial (left) and test (right) space, hence $W^H T(\u03bb) V$ is the projection considered. By specifying  \nprojtype\n to be \n:Galerkin\n then \nW=V\n.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"dep0\",50);\njulia> \u03bb,v=jd_betcke(nep,tol=1e-5,maxit=20);\njulia> norm(compute_Mlincomb(nep,\u03bb[1],v[:,1]))\n1.2277391762692744e-8\n\n\n\n\nReferences\n\n\n\n\nT. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.\n\n\nH. Voss, A Jacobi\u2013Davidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.\n\n\n\n\nSee also\n\n\n\n\nC. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.jd_effenberger\n \u2014 \nFunction\n.\n\n\njd_effenberger([eltype]], nep::ProjectableNEP; [maxit=100], [Neig=1], [inner_solver_method=DefaultInnerSolver], [orthmethod=DGKS], [linsolvercreator=default_linsolvercreator], [tol=eps(real(T))*100], [\u03bb=zero(T)], [v = rand(T,size(nep,1))], [target=zero(T)],  [displaylevel=0])\n\n\n\n\nThe function computes eigenvalues using the Jacobi-Davidson method, which is a projection method. Repreated eigenvalues are avoided by using deflation, as presented in the reference by Effenberger. The projected problems are solved using a solver spcified through the type \ninner_solver_method\n. For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by \northmethod\n, see the package \nIterativeSolvers.jl\n. The function tries to compute \nNeig\n number of eigenvalues, and throws a \nNoConvergenceException\n if it cannot. The value \n\u03bb\n and the vector \nv\n are initial guesses for an eigenpair. \nlinsolvercreator\n is a function which specifies how the linear system is created and solved. The \ntarget\n is the center around which eiganvalues are computed.\n\n\nExample\n\n\njulia> nep=nep_gallery(\"dep0\",100);\njulia> \u03bb,v=jd_effenberger(nep,maxit=30,v=ones(size(nep,1)),\u03bb=0);\njulia> norm(compute_Mlincomb(nep,\u03bb[1],v[:,1]))\n1.902783771915309e-14\n\n\n\n\nReferences\n\n\n\n\nC. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.\n\n\n\n\nSee also\n\n\n\n\nT. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.\n\n\nH. Voss, A Jacobi\u2013Davidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.\n\n\n\n\nsource\n\n\n\n\nArnoldi type methods\n\n\n\n\nIAR\n\n\nThe Infinite ARnoldi method.\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.iar\n \u2014 \nFunction\n.\n\n\niar(nep,[maxit=30,][\u03c3=0,][\u03b3=1,][linsolvecreator=default_linsolvecreator,][tolerance=eps()*10000,][Neig=6,][errmeasure=default_errmeasure,][v=rand(size(nep,1),1),][displaylevel=0,][check_error_every=1,][orthmethod=DGKS])\n\n\n\n\nRun the infinite Arnoldi method on the nonlinear eigenvalue problem stored in \nnep\n.\n\n\nThe target \n\u03c3\n is the center around which eiganvalues are computed. The kwarg \nerrmeasure\n is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair \n\u03bb\n and \nv\n is flagged a as converged (to an eigenpair) if \nerrmeasure\n is less than \ntol\n. The vector \nv\n is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by \northmethod\n, see the package \nIterativeSolvers.jl\n. The iteration is continued until \nNeig\n Ritz pairs converge. This function throws a \nNoConvergenceException\n if the wanted eigenpairs are not computed after \nmaxit\n iterations. The \nlinsolvercreator\n is a function which specifies how the linear system is created and solved.\n\n\nExample\n\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> \u03bb,v=iar(nep;v=v0,tol=1e-5,Neig=3);\njulia> norm(compute_Mlincomb!(nep,\u03bb[1],v[:,1])) # Is it an eigenvalue?\njulia> \u03bb    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n -0.15606211475666945 - 0.12273439802763578im\n -0.15606211475666862 + 0.12273439802763489im\n  0.23169243065648365 - 9.464790582509696e-17im\n\n\n\n\nReferences\n\n\n\n\nAlgorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012\n\n\n\n\nsource\n\n\n\n\nIAR Chebyshev\n\n\nA Chebyshev version of the IAR method.\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.iar_chebyshev\n \u2014 \nFunction\n.\n\n\niar_chebyshev(nep,[maxit=30,][\u03c3=0,][\u03b3=1,][linsolvecreator=default_linsolvecreator,][tolerance=eps()*10000,][Neig=6,][errmeasure=default_errmeasure,][v=rand(size(nep,1),1),][displaylevel=0,][check_error_every=1,][orthmethod=DGKS][a=-1,][b=1,][compute_y0_method=ComputeY0ChebAuto])\n\n\n\n\nRun the infinite Arnoldi method (Chebyshev version) on the nonlinear eigenvalue problem stored in \nnep\n.\n\n\nThe target \n\u03c3\n is the center around which eiganvalues are computed. The kwarg \nerrmeasure\n is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair \n\u03bb\n and \nv\n is flagged a as converged (to an eigenpair) if \nerrmeasure\n is less than \ntol\n. The vector \nv\n is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by \northmethod\n, see the package \nIterativeSolvers.jl\n. The iteration is continued until \nNeig\n Ritz pairs converge. This function throws a \nNoConvergenceException\n if the wanted eigenpairs are not computed after \nmaxit\n iterations. The \nlinsolvercreator\n is a function which specifies how the linear system is created and solved. The kwarg \ncompute_y0_method\n specifying how the next vector of the Krylov space (in Chebyshev format) can be computed. See \ncompute_y0_cheb\n in the module NEPSolver with the command \n?NEPSolver.compute_y0_cheb\n.\n\n\nExample\n\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> \u03bb,v=iar_chebyshev(nep;v=v0,tol=1e-5,Neig=3);\njulia> norm(compute_Mlincomb!(nep,\u03bb[1],v[:,1])) # Is it an eigenvalue?\njulia> \u03bb    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n  -0.1560621117389876 - 0.12273439561483537im\n -0.15606211173898707 + 0.12273439561483517im\n  0.23169252042880578 - 7.86196165647416e-17im\n\n\n\n\nReferences\n\n\n\n\nAlgorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012\n\n\n\n\nsource\n\n\nFor the \niar_chebyshev\n the following \ncompute_y0_cheb\n method is needed, in order to avoid explicit conversions between the Chebyshev basis and the monimial basis.\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.compute_y0_cheb\n \u2014 \nFunction\n.\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.DEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\n\n\n\nComputes the vector y0 used in \niar_chebyshev\n given by\n\n\n$$\n y_0 = \\sum_{i=1}^N T_{i-1}(\u03b3) x_i - \\sum_{j=1}^m A_j \\left( \\sum_{i=1}^{N+1} T_{i-1}(-\u03c1 \\tau_j+\u03b3) y_i \\right )\n$$\n\n\nwhere T(c) is the vector containing $T_i(c)$ as coefficients, where $T_i$ is the i-th Chebyshev polynomial of the first kind.\n\n\nsource\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.PEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\n\n\n\nComputes the vector y0 used in \niar_chebyshev\n given by\n\n\n$$\n y_0 = \\sum_{j=0}^{d-1} A_{j+1} x D^j T(c) - y T(c)\n$$\n\n\nwhere T(c) is the vector containing $T_i(c)$ as coefficients, where $T_i$ is the i-th Chebyshev polynomial of the first kind and $D$ is the derivation matrix in Chebyshev basis.\n\n\nsource\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.SPMF_NEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\n\n\n\nComputes the vector y0 used in \niar_chebyshev\n given by\n\n\n$$\n y_0= \\sum_{j=0}^{m} M^{(j)}(\\mu) X b_j \\left( D_N \\right) T_N(c) - Y T_N(c)\n$$\n\n\nwhere T(c) is the vector containing $T_i(c)$ as coefficients, where $T_i$ is the i-th Chebyshev polynomial of the first kind and $b_j(\\lambda)=(f_j(0)-f_j(\\lambda))/\\lambda=f[\\lambda,0]$ are divided differences.\n\n\nsource\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.NEP,::Type{ComputeY0ChebNEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\n\n\n\nComputes the vector y0 used in \niar_chebyshev\n defined as\n\n\n$$\n y_0 =\\left( \\sum_{i=0}^{N-1} B \\left( \\frac{d}{d \\theta} \\right) \\hat T_i(\\theta) x_i \\right)(0) - \\sum_{i=0}^{N} T_i(c) y_i\n$$\n\n\nwhere $T_i$ is the i-th Chebyshev polynomial of the first kind, $ \\ hat T_i$ is the i-th Chebyshev polynomial of the first kind for the interval [a,b]. For a generic \nnep\n, this quantity is computed by converting polynomials in monomial basis. This procedure may be numerical unstable if many iterations are required. If for the specific \nnep\n a closed formula is available, we suggest to overload this function.\n\n\nsource\n\n\n\n\nTIAR\n\n\nThe Tensor Infinite ARnoldi method.\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.tiar\n \u2014 \nFunction\n.\n\n\ntiar(nep,[maxit=30,][\u03c3=0,][\u03b3=1,][linsolvecreator=default_linsolvecreator,][tolerance=eps()*10000,][Neig=6,][errmeasure=default_errmeasure,][v=rand(size(nep,1),1),][displaylevel=0,][check_error_every=1,][orthmethod=DGKS])\n\n\n\n\nRun the tensor infinite Arnoldi method on the nonlinear eigenvalue problem stored in \nnep\n.\n\n\nThe target \n\u03c3\n is the center around which eiganvalues are computed. The kwarg \nerrmeasure\n is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair \n\u03bb\n and \nv\n is flagged a as converged (to an eigenpair) if \nerrmeasure\n is less than \ntol\n. The vector \nv\n is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by \northmethod\n, see the package \nIterativeSolvers.jl\n. The iteration is continued until \nNeig\n Ritz pairs converge. This function throws a \nNoConvergenceException\n if the wanted eigenpairs are not computed after \nmaxit\n iterations. The \nlinsolvercreator\n is a function which specifies how the linear system is created and solved.\n\n\nExample\n\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> \u03bb,v=tiar(nep;v=v0,tol=1e-5,Neig=3);\njulia> norm(compute_Mlincomb!(nep,\u03bb[1],v[:,1])) # Is it an eigenvalue?\njulia> \u03bb    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n -0.1560621147566685 + 0.12273439802763504im\n -0.1560621147566693 - 0.1227343980276357im\n 0.23169243065648332 - 4.699260229885766e-17im\n\n\n\n\n\nReferences\n\n\n\n\nAlgorithm 2 in Jarlebring, Mele, Runborg, The Waveguide Eigenvalue Problem and the Tensor Infinite Arnoldi Method, SIAM J. Scient. computing, 39 (3), A1062-A1088, 2017\n\n\n\n\nsource\n\n\n\n\nInfbilanczos\n\n\nThe Infinite Bi-Lanczos method.\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.infbilanczos\n \u2014 \nFunction\n.\n\n\n\u03bbv,V,U=infbilanczos([eltype],nep, nept,[linsolvecreator,][linsolvertcreator,][v,][u,][\u03c3,][\u03b3,][tol,][Neig,][errmeasure,][displaylevel,][maxit,][check_error_every])\n\n\n\n\nExecutes the Infinite Bi-Lanczos method on the problem defined by \nnep::NEP\n and \nnept::NEP\n. \nnep:NEP\n is the original nonlinear eigenvalue problem and \nnept::NEP\n is its (hermitian) transpose: $M(\u03bb^*)^H$.  \nv\n and \nu\n are starting vectors, \n\u03c3\n is the shift and \n\u03b3\n the scaling.  See \nnewton()\n for other parameters.\n\n\nExample:\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> A=get_Av(nep); fv=get_fv(nep);\njulia> At=[copy(A[1]'),copy(A[2]'),copy(A[3]')]\njulia> nept=SPMF_NEP(At,fv); # Create the transposed NEP\njulia> \u03bbv,V=infbilanczos(nep,nept,Neig=3)\njulia> norm(compute_Mlincomb(nep,\u03bbv[1],V[:,1]))\n\n\n\n\nReferences:\n\n\n\n\nThe infinite bi-Lanczos method for nonlinear eigenvalue problems, S. W. Gaaf and E. Jarlebring, SIAM J. Sci. Comput. 39:S898-S919, 2017, \npreprint\n\n\n\n\nsource\n\n\n\n\nClass specific methods\n\n\n\n\nCompanion linearizations\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.companion\n \u2014 \nFunction\n.\n\n\nE,A = companion(nep::Pep);\n\n\n\n\nLinearizes a  polynomial eigenvalue problem (PEP) a to the companion form, as in the paper by Mehrmann and Voss. More precisely, for a k-th degree PEP with n-by-n coefficient matrices, this returns matrices E and A, both kn-by-kn, corresponding to the linearized problem\n\n\n$$\nAx = \u03bbEx\n$$\n\n\nExample\n\n\njulia> pep = nep_gallery(\"pep0\");\njulia> E,A = companion(pep);\njulia> \u03bb, V = eigen(A,E);\njulia> minimum(svd(compute_Mder(pep,\u03bb[1])).S)\n2.703104679937224e-12\n\n\n\n\nReferences\n\n\n\n\nV. Mehrmann and H. Voss, Non-linear eigenvalue problems, a challenge for modern eigenvalue methods, GAMM\u2010Mitteilungen (2004)\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPSolver.polyeig\n \u2014 \nFunction\n.\n\n\n\u03bb,v = polyeig([eltype],nep::PEP,[eigsolvertype,])\n\n\nLinearizes a  polynomial eigenvalue problem (PEP) a to the companion form and solves the corresponding linear eigenvalue problem; see \ncompanion\n. The \neigsolvertype\n is optinal can be used to specify how the linear problem is solved; see \neig_solve\n, and \nEigSolver\n.\n\n\nExample\n\n\njulia> pep = nep_gallery(\"pep0\");\njulia> \u03bb,V = polyeig(pep);\njulia> minimum(svd(compute_Mder(pep,\u03bb[1])).S)\n2.1724582040065456e-14\njulia> norm(compute_Mlincomb(pep,\u03bb[2],vec(V[:,2])))\n1.2210363164200074e-12\n\n\n\n\nsource\n\n\n\n\nRational ?",
            "title": "NEP Methods"
        },
        {
            "location": "/methods/#nep-methods",
            "text": "The NEP solver methods implemented in NEP-PACK, are accessed by the functions below. The functions all return $\u03bb,v,w$ where $\u03bb$ is either a number (eigenvalue) a vector of eigenvalues $v$ is either a vector containing an eigenvector or a matrix whose columns corresponding to the eigenvectors.  The first parameter optional parameter in all NEP solver methods is a type. This type specifies which arithmetic should be used for the algorithm.  Example:  julia> nep=nep_gallery(\"dep0\")\njulia> \u03bb,v=augnewton(Complex128,nep,v=ones(5))\n(0.8347353572199425 + 0.0im, Complex{Float64}[0.480386+0.0im, 0.0631636+0.0im, -0.136405+0.0im, 0.214274+0.0im, 0.378581+0.0im])\njulia> typeof(\u03bb)\nComplex{Float64}\njulia> \u03bb,v=augnewton(Float16,nep,v=ones(5))\n(Float16(0.8223), Float16[0.47388, 0.063904, -0.13843, 0.21692, 0.38306])\njulia> typeof(\u03bb)\nFloat16",
            "title": "NEP Methods"
        },
        {
            "location": "/methods/#newton-type-methods",
            "text": "#  NonlinearEigenproblems.NEPSolver.newton  \u2014  Function .  \u03bb,v = newton([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel,][armijo_factor=1,][armijo_max])  Applies Newton-Raphsons method on the system of nonlinear equations with  n+1  unknowns:  $$\nM(\u03bb)v=0\n$$  $$\nc^Hv-1=0\n$$  The kwarg  errmeasure  is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). The iteration is continued until  errmeasure  is less than  tol .  \u03bb  and  v  are starting approximations.  c  is the orthogonalization vector.  If  c=0  the current approximation will be used for the orthogonalization.  armijo_factor  specifies if an Armijo rule should be applied, and its value specifies the scaling factor of the step length (per reduction step). The variable  armijo_max  specifies the maximum number of step length reductions.  Example  julia> nep=nep_gallery(\"dep0\");\njulia> \u03bb,v=newton(nep);\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n1.6066157878930876e-16  References   Nichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.  A. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689   source  #  NonlinearEigenproblems.NEPSolver.augnewton  \u2014  Function .  augnewton([eltype], nep::NEP; [errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel,][linsolvercreator,][armijo_factor,][armijo_max])  Run the augmented Newton method. The method is equivalent to  newton()  in exact arithmetic,  but works only with operations on vectors of length  n . The  linsolvecreator  is used to initiate linear solvers. See  newton()  for other parameters.  Example  This illustrates the equivalence between  newton  and  augnewton .  julia> nep=nep_gallery(\"dep1\")\njulia> \u03bb1,v1=newton(nep,maxit=20,v=ones(size(nep,1)),\u03bb=0)\njulia> \u03bb2,v2=augnewton(nep,maxit=20,v=ones(size(nep,1)),\u03bb=0)\njulia> \u03bb1-\u03bb2\n0.0 + 0.0im  References   Nichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.  A. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689   source  #  NonlinearEigenproblems.NEPSolver.resinv  \u2014  Function .  \u03bb,v = resinv([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel,][armijo_factor=1,][armijo_max,][linsolvecreator])  Applies residual inverse iteration method for nonlinear eigenvalue problems. The kwarg  linsolvecreator  is a function which specifies how the linear system is created. The function calls  compute_rf  for the computation of the Rayleigh functional. See  newton()  for other parameters.  Example  The example shows how to specify if the method should run in real or complex mode (or any other  Number  type).  julia> nep=nep_gallery(\"qdep0\");\njulia> \u03bb,v=resinv(nep,\u03bb=-2,v=ones(size(nep,1)))\njulia> typeof(\u03bb)\nComplex{Float64}\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n1.817030659827106e-14\njulia> \u03bb,v=resinv(Float64,nep,\u03bb=-2,v=ones(size(nep,1)))\njulia> typeof(\u03bb)\nFloat64\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n1.817030659827106e-14  References   A. Neumaier, Residual inverse iteration for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 22 (1985) 914-923   source  #  NonlinearEigenproblems.NEPSolver.quasinewton  \u2014  Function .  quasinewton([T=ComplexF64],nep,[errmeasure,][tol,][maxit,][\u03bb,][v][ws][displaylevel][linsolvercreator,][armijo_factor,][armijo_max])  An implementation of the quasi-Newton approach referred to as quasi-Newton 2 in the reference. The method involves one linear system solve per iteration corresponding with the matrix $M(\u03bb)$, where $\u03bb$ is constant. The vector  ws  is a representation of the normalization, in the sense that $c^T=w_s^TM(\u03bb)$, where all iterates satisfy $c^Tx_i=1$. See  newton()  for other parameters.  Example  julia> nep=nep_gallery(\"pep0\")\njulia> \u03bb,v=quasinewton(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n6.301479387102376e-15  References   Jarlebring, Koskela, Mele, Disguised and new Quasi-Newton methods for nonlinear eigenvalue problems, Numer. Algorithms, 79:311-335, 2018.  preprint   source  #  NonlinearEigenproblems.NEPSolver.mslp  \u2014  Function .   mslp([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][displaylevel,][eigsolvertype::DataType][armijo_factor=1,][armijo_max])  Runs the method of successive linear problems. The  method requires the solution of a generalized eigenvalue problem in every iteration. The method used for the eigenvalue computation is specified in eigsolvertype. See  newton  for other parameters.  Example  Create a rational NEP with SPMFs.  julia> Av=[ones(3,3),eye(3,3),triu(ones(3,3))];\njulia> fv=[S-> S, S -> S^2, S::AbstractArray -> inv(Matrix(S)-eye(S)*10)]\njulia> nep=SPMF_NEP(Av,fv)\njulia> (\u03bb,v)=mslp(nep)\njulia> compute_Mlincomb(nep,\u03bb,v)\n3-element Array{Complex{Float64},1}:\n -1.38778e-17+1.65715e-18im\n -5.55112e-17+1.30633e-17im\n -4.16334e-17-1.54436e-17im  References   A. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689   source  #  NonlinearEigenproblems.NEPSolver.rfi  \u2014  Function .  rfi(nep,nept,[\u03bb=0,][errmeasure=default_errmeasure,][tol=eps()*100,][maxit=100,][v=randn,][u=randn,][displaylevel=0,][linsolvecreator=default_linsolvecreator,])  This is an implementation of the two-sided Rayleigh functional Iteration (RFI) to compute an eigentriplet of the problem specified by  nep . This method requires the transpose of the NEP, specified in  nept .  \u03bb ,  u  and  v  are initial guesses for the eigenvalue, the right eigenvector and the left eigenvector respectively. A  NoConvergenceException  is thrown if an eigentriplet is not found in  maxit  iterations.  Example  julia> nep=nep_gallery(\"dep0\");\njulia> nept=DEP([nep.A[1]',nep.A[2]'])\njulia> \u03bb,v,u=rfi_b(nep,nept)\njulia> compute_resnorm(nep,\u03bb,v) % v is a right eigenvector\n4.347204570675246e-16\njulia> compute_resnorm(nept,\u03bb,u) % u is a left eigenvector\n7.173081573164097e-16  Reference   Algorithm 4 in  Schreiber, Nonlinear Eigenvalue Problems: Newton-type Methods and Nonlinear Rayleigh Functionals, PhD thesis, TU Berlin, 2008.   source  #  NonlinearEigenproblems.NEPSolver.newtonqr  \u2014  Function .  \u03bb,v = newtonqr([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel])  This function implements the Newton-QR method as formulated in the reference. The method ivolves the computation of a rank-revealing QR factorization of $M(\u03bb)$, with the idea that on convergence the the last diagonal element $R[n,n]$ of the upper-triangular matrix $R$ becomes zero as a result of $M(\u03bb)$ becoming singular. Since the computation of a QR factorization is expensive, it is advisable to use this method for problems of small size or problems with a certain structure that makes the QR computation less expensive. See  newton  for description of the function arguements.  Example  julia> nep=nep_gallery(\"pep0\")\njulia> \u03bb,v=newtonqr(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n1.0442559980785471e-14  References   Kublanovskaya, V. N., (1970).  On an approach to the solution of the generalized latent value problem for \u03bb-matrices, SIAM J. Numer. Anal. 7, 532\u2013537  G\u00fcttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034   source  #  NonlinearEigenproblems.NEPSolver.implicitdet  \u2014  Function .  \u03bb,v = implicitdet([eltype],nep::NEP;[errmeasure,][tol,][maxit,][\u03bb,][v,][c,][displaylevel])  This function implements the Implicit determinant method as formulated Algorithm 4.3 in the reference. The method applies Newton-Raphson to the equation $det(M(\u03bb))/det(G(\u03bb)) = 0$, where $G(\u03bb)$ is a saddle point matrix with $M(\u03bb)$ in the (1,1) block. The (2,1) and (1,2) blocks of $G(\u03bb)$ are set to $c^H$ and $c$ respectively. Note that $G(\u03bb)$ can be non-singular even when $M(\u03bb)$ is singular. See reference for more information. See  newton  for description of the function arguements.  Example  julia> nep=nep_gallery(\"pep0\")\njulia> \u03bb,v=implicitdet(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n3.75723275262885e-14  References   Spence, A., & Poulton, C. (2005). Photonic band structure calculations using nonlinear eigenvalue techniques, J. Comput. Phys., 204 (2005), pp. 65\u20138  G\u00fcttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034   source  #  NonlinearEigenproblems.NEPSolver.broyden  \u2014  Function .  S,V = broyden([eltype,]nep::NEP[,approxnep::NEP];kwargs)  Runs Broydens method (with deflation) for the nonlinear eigenvalue problem defined by nep. An approximate nep can be provided which is used as an initialization of starting matrix/vectors.  The method computes an invariant pair and can therefore find several eigenvalues. The retured value is (S,V) is an invariant pair and the eigenvalues are on the diagonal of S.  Example  julia> nep=nep_gallery(\"dep0\");\njulia> S,V=broyden(nep);\njulia> \u03bb=S[1,1]\n-0.3587189459686267 - 3.0010731412746105e-31im\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n1.6066157878930856e-16\njulia> \u03bb=S[2,2]\n-0.04093521177097334 + 1.486011530941621im\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n4.159109513753696e-16\njulia> \u03bb=S[3,3]\n0.8347353572199486 + 1.5032076225139986e-14im\njulia> minimum(svdvals(compute_Mder(nep,\u03bb)))\n1.296144276122994e-14\njulia> broyden(nep,displaylevel=2,check_error_every=1);  % Prints out a lot more convergence info  References   Jarlebring, Broyden\u2019s method for nonlinear eigenproblems, 2018, https://arxiv.org/pdf/1802.07322   source",
            "title": "Newton type methods"
        },
        {
            "location": "/methods/#projection-methods",
            "text": "#  NonlinearEigenproblems.NEPSolver.nlar  \u2014  Function .  function nlar([eltype],nep::ProjectableNEP,[orthmethod=ModifiedGramSchmidt],[neigs=10],[errmeasure=default_errmeasure],[tol=eps(real(T))*100],[maxit=100],[\u03bb0=0],[v0=randn(T,size(nep,1))],[displaylevel=0],[linsolvercreator=default_linsolvercreator],[R=0.01],[eigval_sorter=residual_eigval_sorter],[qrfact_orth=false],[max_subspace=100],[num_restart_ritz_vecs=8],[inner_solver_method=DefaultInnerSolver])  The function implements the Nonlinear Arnoldi method, which finds  neigs  eigenpairs(or throws a  NoConvergenceException ) by projecting the problem to a subspace that is expanded in the course  of the algorithm. The basis is orthogonalized either by using the QR method if  qrfact_orth  is  true  or else by an orthogonalization method  orthmethod ). This entails solving a smaller projected problem using a method specified by  inner_solver_method . ( \u03bb0 , v0 ) is the initial guess for the eigenpair.  linsolvercreator  specifies how the linear system is created and solved.  R  is a parameter used by the function specified by  eigval_sorter  to reject those ritz values that are within a distance  R  from any of the converged eigenvalues, so that repeated convergence to the same eigenpair can be avoided.  max_subspace  is the maximum allowable size of the basis befor the algorithm restarts using a basis made of  num_restart_ritz_vecs  ritz vectors and the eigenvectors that the algorithm has converged to.  Example  julia> nep=nep_gallery(\"dep0_tridiag\");\njulia> \u03bb,v=nlar(nep,tol=1e-5,neigs=1,maxit=50);\njulia> norm(compute_Mlincomb(nep,\u03bb[1],v))\n7.722757003764154e-7  References   H. Voss, An Arnoldi method for nonlinear eigenvalue problems. BIT. Numer. Math. 44: 387-401, 2004.   source  #  NonlinearEigenproblems.NEPSolver.jd_betcke  \u2014  Function .  jd_betcke([eltype]], nep::ProjectableNEP; [Neig=1], [tol=eps(real(T))*100], [maxit=100], [\u03bb=zero(T)], [orthmethod=DGKS],  [errmeasure=default_errmeasure], [linsolvercreator=default_linsolvercreator], [v = randn(size(nep,1))], [displaylevel=0], [inner_solver_method=DefaultInnerSolver], [projtype=:PetrovGalerkin], [target=zero(T)])  The function computes eigenvalues using Jacobi-Davidson method, which is a projection method. The projected problems are solved using a solver spcified through the type  inner_solver_method . For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by  orthmethod , see the package  IterativeSolvers.jl . The function tries to compute  Neig  number of eigenvalues, and throws a  NoConvergenceException  if it cannot. The value  \u03bb  and the vector  v  are initial guesses for an eigenpair.  linsolvercreator  is a function which specifies how the linear system is created and solved. The  target  is the center around which eiganvlues are computed.  errmeasure  is a function handle which can be used to specify how the error is measured. By default the method uses a Petrov-Galerkin framework, with a trial (left) and test (right) space, hence $W^H T(\u03bb) V$ is the projection considered. By specifying   projtype  to be  :Galerkin  then  W=V .  Example  julia> nep=nep_gallery(\"dep0\",50);\njulia> \u03bb,v=jd_betcke(nep,tol=1e-5,maxit=20);\njulia> norm(compute_Mlincomb(nep,\u03bb[1],v[:,1]))\n1.2277391762692744e-8  References   T. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.  H. Voss, A Jacobi\u2013Davidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.   See also   C. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.   source  #  NonlinearEigenproblems.NEPSolver.jd_effenberger  \u2014  Function .  jd_effenberger([eltype]], nep::ProjectableNEP; [maxit=100], [Neig=1], [inner_solver_method=DefaultInnerSolver], [orthmethod=DGKS], [linsolvercreator=default_linsolvercreator], [tol=eps(real(T))*100], [\u03bb=zero(T)], [v = rand(T,size(nep,1))], [target=zero(T)],  [displaylevel=0])  The function computes eigenvalues using the Jacobi-Davidson method, which is a projection method. Repreated eigenvalues are avoided by using deflation, as presented in the reference by Effenberger. The projected problems are solved using a solver spcified through the type  inner_solver_method . For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by  orthmethod , see the package  IterativeSolvers.jl . The function tries to compute  Neig  number of eigenvalues, and throws a  NoConvergenceException  if it cannot. The value  \u03bb  and the vector  v  are initial guesses for an eigenpair.  linsolvercreator  is a function which specifies how the linear system is created and solved. The  target  is the center around which eiganvalues are computed.  Example  julia> nep=nep_gallery(\"dep0\",100);\njulia> \u03bb,v=jd_effenberger(nep,maxit=30,v=ones(size(nep,1)),\u03bb=0);\njulia> norm(compute_Mlincomb(nep,\u03bb[1],v[:,1]))\n1.902783771915309e-14  References   C. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.   See also   T. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.  H. Voss, A Jacobi\u2013Davidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.   source",
            "title": "Projection methods"
        },
        {
            "location": "/methods/#arnoldi-type-methods",
            "text": "",
            "title": "Arnoldi type methods"
        },
        {
            "location": "/methods/#iar",
            "text": "The Infinite ARnoldi method.  #  NonlinearEigenproblems.NEPSolver.iar  \u2014  Function .  iar(nep,[maxit=30,][\u03c3=0,][\u03b3=1,][linsolvecreator=default_linsolvecreator,][tolerance=eps()*10000,][Neig=6,][errmeasure=default_errmeasure,][v=rand(size(nep,1),1),][displaylevel=0,][check_error_every=1,][orthmethod=DGKS])  Run the infinite Arnoldi method on the nonlinear eigenvalue problem stored in  nep .  The target  \u03c3  is the center around which eiganvalues are computed. The kwarg  errmeasure  is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair  \u03bb  and  v  is flagged a as converged (to an eigenpair) if  errmeasure  is less than  tol . The vector  v  is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by  orthmethod , see the package  IterativeSolvers.jl . The iteration is continued until  Neig  Ritz pairs converge. This function throws a  NoConvergenceException  if the wanted eigenpairs are not computed after  maxit  iterations. The  linsolvercreator  is a function which specifies how the linear system is created and solved.  Example  julia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> \u03bb,v=iar(nep;v=v0,tol=1e-5,Neig=3);\njulia> norm(compute_Mlincomb!(nep,\u03bb[1],v[:,1])) # Is it an eigenvalue?\njulia> \u03bb    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n -0.15606211475666945 - 0.12273439802763578im\n -0.15606211475666862 + 0.12273439802763489im\n  0.23169243065648365 - 9.464790582509696e-17im  References   Algorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012   source",
            "title": "IAR"
        },
        {
            "location": "/methods/#iar-chebyshev",
            "text": "A Chebyshev version of the IAR method.  #  NonlinearEigenproblems.NEPSolver.iar_chebyshev  \u2014  Function .  iar_chebyshev(nep,[maxit=30,][\u03c3=0,][\u03b3=1,][linsolvecreator=default_linsolvecreator,][tolerance=eps()*10000,][Neig=6,][errmeasure=default_errmeasure,][v=rand(size(nep,1),1),][displaylevel=0,][check_error_every=1,][orthmethod=DGKS][a=-1,][b=1,][compute_y0_method=ComputeY0ChebAuto])  Run the infinite Arnoldi method (Chebyshev version) on the nonlinear eigenvalue problem stored in  nep .  The target  \u03c3  is the center around which eiganvalues are computed. The kwarg  errmeasure  is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair  \u03bb  and  v  is flagged a as converged (to an eigenpair) if  errmeasure  is less than  tol . The vector  v  is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by  orthmethod , see the package  IterativeSolvers.jl . The iteration is continued until  Neig  Ritz pairs converge. This function throws a  NoConvergenceException  if the wanted eigenpairs are not computed after  maxit  iterations. The  linsolvercreator  is a function which specifies how the linear system is created and solved. The kwarg  compute_y0_method  specifying how the next vector of the Krylov space (in Chebyshev format) can be computed. See  compute_y0_cheb  in the module NEPSolver with the command  ?NEPSolver.compute_y0_cheb .  Example  julia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> \u03bb,v=iar_chebyshev(nep;v=v0,tol=1e-5,Neig=3);\njulia> norm(compute_Mlincomb!(nep,\u03bb[1],v[:,1])) # Is it an eigenvalue?\njulia> \u03bb    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n  -0.1560621117389876 - 0.12273439561483537im\n -0.15606211173898707 + 0.12273439561483517im\n  0.23169252042880578 - 7.86196165647416e-17im  References   Algorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012   source  For the  iar_chebyshev  the following  compute_y0_cheb  method is needed, in order to avoid explicit conversions between the Chebyshev basis and the monimial basis.  #  NonlinearEigenproblems.NEPSolver.compute_y0_cheb  \u2014  Function .  y0 = compute_y0_cheb([eltype],nep::NEPTypes.DEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)  Computes the vector y0 used in  iar_chebyshev  given by  $$\n y_0 = \\sum_{i=1}^N T_{i-1}(\u03b3) x_i - \\sum_{j=1}^m A_j \\left( \\sum_{i=1}^{N+1} T_{i-1}(-\u03c1 \\tau_j+\u03b3) y_i \\right )\n$$  where T(c) is the vector containing $T_i(c)$ as coefficients, where $T_i$ is the i-th Chebyshev polynomial of the first kind.  source  y0 = compute_y0_cheb([eltype],nep::NEPTypes.PEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)  Computes the vector y0 used in  iar_chebyshev  given by  $$\n y_0 = \\sum_{j=0}^{d-1} A_{j+1} x D^j T(c) - y T(c)\n$$  where T(c) is the vector containing $T_i(c)$ as coefficients, where $T_i$ is the i-th Chebyshev polynomial of the first kind and $D$ is the derivation matrix in Chebyshev basis.  source  y0 = compute_y0_cheb([eltype],nep::NEPTypes.SPMF_NEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)  Computes the vector y0 used in  iar_chebyshev  given by  $$\n y_0= \\sum_{j=0}^{m} M^{(j)}(\\mu) X b_j \\left( D_N \\right) T_N(c) - Y T_N(c)\n$$  where T(c) is the vector containing $T_i(c)$ as coefficients, where $T_i$ is the i-th Chebyshev polynomial of the first kind and $b_j(\\lambda)=(f_j(0)-f_j(\\lambda))/\\lambda=f[\\lambda,0]$ are divided differences.  source  y0 = compute_y0_cheb([eltype],nep::NEPTypes.NEP,::Type{ComputeY0ChebNEP},X,Y,M0inv,precomp::AbstractPrecomputeData)  Computes the vector y0 used in  iar_chebyshev  defined as  $$\n y_0 =\\left( \\sum_{i=0}^{N-1} B \\left( \\frac{d}{d \\theta} \\right) \\hat T_i(\\theta) x_i \\right)(0) - \\sum_{i=0}^{N} T_i(c) y_i\n$$  where $T_i$ is the i-th Chebyshev polynomial of the first kind, $ \\ hat T_i$ is the i-th Chebyshev polynomial of the first kind for the interval [a,b]. For a generic  nep , this quantity is computed by converting polynomials in monomial basis. This procedure may be numerical unstable if many iterations are required. If for the specific  nep  a closed formula is available, we suggest to overload this function.  source",
            "title": "IAR Chebyshev"
        },
        {
            "location": "/methods/#tiar",
            "text": "The Tensor Infinite ARnoldi method.  #  NonlinearEigenproblems.NEPSolver.tiar  \u2014  Function .  tiar(nep,[maxit=30,][\u03c3=0,][\u03b3=1,][linsolvecreator=default_linsolvecreator,][tolerance=eps()*10000,][Neig=6,][errmeasure=default_errmeasure,][v=rand(size(nep,1),1),][displaylevel=0,][check_error_every=1,][orthmethod=DGKS])  Run the tensor infinite Arnoldi method on the nonlinear eigenvalue problem stored in  nep .  The target  \u03c3  is the center around which eiganvalues are computed. The kwarg  errmeasure  is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair  \u03bb  and  v  is flagged a as converged (to an eigenpair) if  errmeasure  is less than  tol . The vector  v  is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by  orthmethod , see the package  IterativeSolvers.jl . The iteration is continued until  Neig  Ritz pairs converge. This function throws a  NoConvergenceException  if the wanted eigenpairs are not computed after  maxit  iterations. The  linsolvercreator  is a function which specifies how the linear system is created and solved.  Example  julia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> \u03bb,v=tiar(nep;v=v0,tol=1e-5,Neig=3);\njulia> norm(compute_Mlincomb!(nep,\u03bb[1],v[:,1])) # Is it an eigenvalue?\njulia> \u03bb    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n -0.1560621147566685 + 0.12273439802763504im\n -0.1560621147566693 - 0.1227343980276357im\n 0.23169243065648332 - 4.699260229885766e-17im  References   Algorithm 2 in Jarlebring, Mele, Runborg, The Waveguide Eigenvalue Problem and the Tensor Infinite Arnoldi Method, SIAM J. Scient. computing, 39 (3), A1062-A1088, 2017   source",
            "title": "TIAR"
        },
        {
            "location": "/methods/#infbilanczos",
            "text": "The Infinite Bi-Lanczos method.  #  NonlinearEigenproblems.NEPSolver.infbilanczos  \u2014  Function .  \u03bbv,V,U=infbilanczos([eltype],nep, nept,[linsolvecreator,][linsolvertcreator,][v,][u,][\u03c3,][\u03b3,][tol,][Neig,][errmeasure,][displaylevel,][maxit,][check_error_every])  Executes the Infinite Bi-Lanczos method on the problem defined by  nep::NEP  and  nept::NEP .  nep:NEP  is the original nonlinear eigenvalue problem and  nept::NEP  is its (hermitian) transpose: $M(\u03bb^*)^H$.   v  and  u  are starting vectors,  \u03c3  is the shift and  \u03b3  the scaling.  See  newton()  for other parameters.  Example:  julia> nep=nep_gallery(\"dep0\");\njulia> A=get_Av(nep); fv=get_fv(nep);\njulia> At=[copy(A[1]'),copy(A[2]'),copy(A[3]')]\njulia> nept=SPMF_NEP(At,fv); # Create the transposed NEP\njulia> \u03bbv,V=infbilanczos(nep,nept,Neig=3)\njulia> norm(compute_Mlincomb(nep,\u03bbv[1],V[:,1]))  References:   The infinite bi-Lanczos method for nonlinear eigenvalue problems, S. W. Gaaf and E. Jarlebring, SIAM J. Sci. Comput. 39:S898-S919, 2017,  preprint   source",
            "title": "Infbilanczos"
        },
        {
            "location": "/methods/#class-specific-methods",
            "text": "",
            "title": "Class specific methods"
        },
        {
            "location": "/methods/#companion-linearizations",
            "text": "#  NonlinearEigenproblems.NEPSolver.companion  \u2014  Function .  E,A = companion(nep::Pep);  Linearizes a  polynomial eigenvalue problem (PEP) a to the companion form, as in the paper by Mehrmann and Voss. More precisely, for a k-th degree PEP with n-by-n coefficient matrices, this returns matrices E and A, both kn-by-kn, corresponding to the linearized problem  $$\nAx = \u03bbEx\n$$  Example  julia> pep = nep_gallery(\"pep0\");\njulia> E,A = companion(pep);\njulia> \u03bb, V = eigen(A,E);\njulia> minimum(svd(compute_Mder(pep,\u03bb[1])).S)\n2.703104679937224e-12  References   V. Mehrmann and H. Voss, Non-linear eigenvalue problems, a challenge for modern eigenvalue methods, GAMM\u2010Mitteilungen (2004)   source  #  NonlinearEigenproblems.NEPSolver.polyeig  \u2014  Function .  \u03bb,v = polyeig([eltype],nep::PEP,[eigsolvertype,])  Linearizes a  polynomial eigenvalue problem (PEP) a to the companion form and solves the corresponding linear eigenvalue problem; see  companion . The  eigsolvertype  is optinal can be used to specify how the linear problem is solved; see  eig_solve , and  EigSolver .  Example  julia> pep = nep_gallery(\"pep0\");\njulia> \u03bb,V = polyeig(pep);\njulia> minimum(svd(compute_Mder(pep,\u03bb[1])).S)\n2.1724582040065456e-14\njulia> norm(compute_Mlincomb(pep,\u03bb[2],vec(V[:,2])))\n1.2210363164200074e-12  source",
            "title": "Companion linearizations"
        },
        {
            "location": "/methods/#rational",
            "text": "",
            "title": "Rational ?"
        },
        {
            "location": "/types/",
            "text": "NEPTypes\n\n\n\n\nThe basic type\n\n\nThe basic class is the abstract class \nNEP\n which represents a NEP. All other defined NEPs should inherit from \nNEP\n, or from a more specialized version; see, e.g., \nProjectableNEP\n or \nAbstractSPMF\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPCore.NEP\n \u2014 \nType\n.\n\n\nabstract NEP\n\n\n\n\nA \nNEP\n object represents a nonlinear eigenvalue problem. All NEPs should implement\n\n\nsize(nep::NEP,d)\n\n\n\n\nand at least one of the following\n\n\n\n\nM = \ncompute_Mder(nep::NEP,\u03bb::Number,i::Integer=0)\n\n\nV = \ncompute_Mlincomb!(nep::NEP,\u03bb::Number,V::AbstractVecOrMat,a::Vector)\n\n\nMM = \ncompute_MM(nep::NEP,S,V)\n\n\n\n\nsource\n\n\nBelow we list the most common types built-in to NEP-PACK, and further down how you can \naccess the NEP\n. However, the structure is made for extendability, and hence it is possible for you to extend with your own class of NEPs.\n\n\n\n\nSPMF\n\n\nOne of the most common problem types is the \nSPMF_NEP\n. SPMF is short for Sum of Products of Matrices and Functions and the NEP is described by\n\n\n$$\nM(\u03bb) = \\sum_{i} A_i f_i(\u03bb).\n$$\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.SPMF_NEP\n \u2014 \nType\n.\n\n\nstruct SPMF_NEP{T<:AbstractMatrix,Ftype}  <: AbstractSPMF{T}\n\n\n\n\nAn SPMF_NEP is a NEP defined by a Sum of Products of Matrices and Functions, i.e.,\n\n\n$$\nM(\u03bb)=\u2211_i A_i f_i(\u03bb).\n$$\n\n\nAll of the matrices $A_0,...$ are of size $n\u00d7n$ and $f_i$ are a functions. The  functions $f_i$ must be defined for matrices in the standard matrix function sense.\n\n\nsource\n\n\nIn order to construct an \nSPMF_NEP\n, we need to provide the matrices and the functions.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.SPMF_NEP\n \u2014 \nMethod\n.\n\n\n SPMF_NEP(AA, fii, check_consistency, Schur_fact = false, align_sparsity_patterns = false, , Ftype)\n\n\n\n\nCreates a \nSPMF_NEP\n consisting of matrices \nAA\n and functions \nfii\n. The \nSPMF_NEP\n is defined by a sum of products of matrices and functions\n\n\n$$\nM(\u03bb)=\u2211_i A_i f_i(\u03bb).\n$$\n\n\nAll of the matrices $A_0,...$ are of size $n\u00d7n$ and $f_i$ are a functions. The  functions $f_i$ must be defined for matrices in the standard matrix function sense.\n\n\nParameters\n\n\n\n\nAA\n is a \nVector\n of matrices. The matrices have to be of the same type. If you need a NEP with different types you can use \nSumNEP\n to construct a sum of two \nSPMF_NEP\n.\n\n\nfii\n is a \nVector\n of functions. Each function takes one parameter \nS\n. The functions must be available both as a scalar valid function and a matrix function. If \nS\n is a square matrix, \nfii[k](S)\n musst also be a square matrix. If \nS\n is a scalar \nfii[k](S)\n is a scalar.\n\n\ncheck_consistency\n (default \ntrue\n) determines if we should initiate by running tests to verify that the \nfii\n satisfies the conditions that every function is valid both for matrices and scalars. This is done by using \n@code_typed\n and the functions need to be type-stable in that sense.\n\n\nalign_sparsity_patterns\n (default \nfalse\n) has effect only for sparse matrices (\nSparseMatrixCSC\n). If \nalign_sparsity_patterns=true\n the \nSparseMatrixCSC\n matrices will be replaced by equivalent \nSparseMatrixCSC\n matrices where the \ncolptr\n and \nrowval\n are identical. This increases the speed of some functions, e.g., \ncompute_Mder\n. If \nalign_sparsity_patterns=true\n the matrices in the NEP should be considered read only. If the sparsity patterns are completely or mostly distinct, it may be more efficient to set this flag to false.\n\n\nFtype\n (default \nComplexF64\n) determines an underlying type of the functions. The output of any function should be \"smaller\" than the promoted type of the input and \nFtype\n. More precisely, if \nF=fii[k]\n, then the type logic is as follows \neltype(F(\u03bb))=promote_type(eltype(\u03bb),Ftype)\n.\n\n\nSchur_fact\n (default \nfalse\n) determines if the \ncompute_MM\n function should tridiagonalize the matrix before carrying out the computation. This can be faster for large matrices.\n\n\n\n\nExample\n\n\njulia> A0=[1 3; 4 5]; A1=[3 4; 5 6];\njulia> id_op=S -> one(S) # Note: We use one(S) to be valid both for matrices and scalars\njulia> exp_op=S -> exp(S)\njulia> nep=SPMF_NEP([A0,A1],[id_op,exp_op]);\njulia> compute_Mder(nep,1)-(A0+A1*exp(1))\n2\u00d72 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\n\n\n\nsource\n\n\n\n\nAbstract SPMFs\n\n\nMany problems can be described in the class of SPMF. There might be more specialized and efficient implementations such as, e.g. \nPEP\n, \nDEP\n or \nREP\n. However, on an abstract level it may still be important to recognize the similarities. Hence there is an abstract class \nAbstractSPMF\n, which in itself inherits from \nProjectableNEP\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.AbstractSPMF\n \u2014 \nType\n.\n\n\nabstract  AbstractSPMF <: ProjectableNEP\n\n\n\n\nAn AbstractSPMF is an abstract class representing NEPs which can be represented as a Sum of products of matrices and functions $M(\u03bb)=\u03a3_i A_i f_i(\u03bb)$, where i = 0,1,2,..., all of the matrices are of size n times n and f_i are functions.\n\n\nAny AbstractSPMF has to have implementations of \nget_Av()\n and \nget_fv()\n which return the functions and matrices.\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.get_Av\n \u2014 \nFunction\n.\n\n\nget_Av(nep::AbstractSPMF)\n\n\n\n\nReturns an array of matrices $A_i$ in the AbstractSPMF: $M(\u03bb)=\u03a3_i A_i f_i(\u03bb)$\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.get_fv\n \u2014 \nFunction\n.\n\n\nget_Av(nep::AbstractSPMF)\n\n\n\n\nReturns an Array of functions (that can be evaluated both as scalar and matrix functions) $f_i$ in the AbstractSPMF: $M(\u03bb)=\u03a3_i A_i f_i(\u03bb)$\n\n\nsource\n\n\n\n\nPEP\n\n\nThe Polynomial Eigenvalue Problem is described by\n\n\n$$\nM(\u03bb) = \\sum_{i} A_i \u03bb^i.\n$$\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.PEP\n \u2014 \nType\n.\n\n\nstruct PEP <: AbstractSPMF\n\n\n\n\nA polynomial eigenvalue problem (PEP) is defined by the sum the sum $\u03a3_i A_i \u03bb^i$, where i = 0,1,2,..., and  all of the matrices are of size n times n.\n\n\nsource\n\n\nIn order to construct a \nPEP\n, we only need to provide the matrices.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.PEP\n \u2014 \nMethod\n.\n\n\nPEP(AA::Array)\n\n\n\n\nCreates a polynomial eigenvalue problem with monomial matrices specified in AA, which is an array of matrices.\n\n\njulia> A0=[1 3; 4 5]; A1=A0.+one(2); A2=ones(2,2);\njulia> pep=PEP([A0,A1,A2])\njulia> compute_Mder(pep,3)-(A0+A1*3+A2*9)\n2\u00d72 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\n\n\n\nsource\n\n\n\n\nDEP\n\n\nThe Delay Eigenvalue Problem is described by\n\n\n$$\nM(\u03bb) = -\u03bbI + \\sum_{i} A_i e^{-\u03c4_i \u03bb}.\n$$\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.DEP\n \u2014 \nType\n.\n\n\ntype DEP <: AbstractSPMF\n\n\n\n\nA DEP (Delay Eigenvalue problem) is defined by the sum  $-\u03bbI + \u03a3_i A_i exp(-tau_i \u03bb)$ where all of the matrices are of size n times n.\nConstructor: \nDEP(AA,tauv)\n where \nAA\n is an array of the matrices $A_i$, and \ntauv\n is a vector of the values  $tau_i$.\n\n\nExample:\n\n\njulia> A0=randn(3,3); A1=randn(3,3);\njulia> tauv=[0,0.2] # Vector with delays\njulia> dep=DEP([A0,A1],tauv)\njulia> \u03bb=3.0;\njulia> M1=compute_Mder(dep,\u03bb)\njulia> M2=-\u03bb*I+A0+A1*exp(-tauv[2]*\u03bb)\njulia> norm(M1-M2)\n0.0\n\n\n\n\nsource\n\n\n\n\nREP\n\n\nThe Rational Eigenvalue Problem is described by:\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.REP\n \u2014 \nType\n.\n\n\nstruct REP <: AbstractSPMF\n\n\n\n\nA REP represents a rational eigenvalue problem. The REP is defined by the sum $\u03a3_i A_i s_i(\u03bb)/q_i(\u03bb)$, where i = 0,1,2,..., all of the matrices are of size n times n and s\ni and q\ni are polynomials.\n\n\nsource\n\n\nThe constructor is called as:\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.REP\n \u2014 \nMethod\n.\n\n\nREP(A,poles)\n\n\n\n\nCreates a rational eigenvalue problem. The constructor takes the matrices A_i and a sequence of poles as input (not complete).\n\n\nExample\n\n\njulia> A0=[1 2; 3 4]; A1=[3 4; 5 6];\njulia> nep=REP([A0,A1],[1,3]);\njulia> compute_Mder(nep,3)\n2\u00d72 Array{Float64,2}:\n NaN  NaN\n NaN  NaN\n\n\n\n\nsource\n\n\n\n\nSumNEP\n\n\nIt is also possible to consider NEPs that are summs of other NEPs. For such situations there are SumNEPs. Specifically \nGenericSumNEP\n and \nSPMFSumNEP\n. Both are constructed using the function \nSumNEP\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.SumNEP\n \u2014 \nFunction\n.\n\n\nSumNEP{nep1::NEP,nep2::NEP}\nSumNEP{nep1::AbstractSPMF,nep2::AbstractSPMF}\n\n\n\n\nSumNEP is a function creating an object that corresponds to a sum of two NEPs, i.e., if nep is created by SumNEP it is defined by\n\n\n$$\nM(\u03bb)=M_1(\u03bb)+M_2(\u03bb)\n$$\n\n\nwhere M\n1 and M\n2 are defined by \nnep1\n and \nnep2\n.\n\n\nExample:\n\n\njulia> nep1=DEP([ones(3,3),randn(3,3)])\njulia> nep2=PEP([ones(3,3),randn(3,3),randn(3,3)])\njulia> sumnep=SumNEP(nep1,nep2);\njulia> s=3.0;\njulia> M=compute_Mder(sumnep,s);\n3\u00d73 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828\njulia> M1=compute_Mder(nep1,s);\njulia> M2=compute_Mder(nep2,s);\njulia> M1+M2  # Same as M\n3\u00d73 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828\n\n\n\n\nSee also: \nSPMFSumNEP\n, \nGenericSumNEP\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.GenericSumNEP\n \u2014 \nType\n.\n\n\nstruct GenericSumNEP{NEP1<:NEP,NEP2<:NEP}  <: NEP\n\n\n\n\nSee also: \nSumNEP\n, \nSPMFSumNEP\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.SPMFSumNEP\n \u2014 \nType\n.\n\n\nstruct SPMFSumNEP{NEP1<:AbstractSPMF,NEP2<:AbstractSPMF}  <: AbstractSPMF{AbstractMatrix}\n\n\n\n\nSee also: \nSumNEP\n, \nGenericSumNEP\n\n\nsource\n\n\n\n\nAccessing the NEP\n\n\n\n\nThe nonlinear eigenvalue problem is defined by the data stored in the NEP-class, and the NEP-solvers access the data mainly through three main functions, \ncompute_Mder\n \ncompute_Mlincomb\n and \ncompute_MM\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPCore.compute_Mder\n \u2014 \nFunction\n.\n\n\ncompute_Mder(nep::NEP,\u03bb::Number [,i::Integer=0])\n\n\n\n\nComputes the ith derivative of \nnep\n evaluated in \n\u03bb\n.\n\n\nExample\n\n\nThis example shows that \ncompute_Mder(nep,\u03bb,1)\n gives the first derivative.\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> \u03f5=1e-5;\njulia> Aminus=compute_Mder(nep,\u03bb-\u03f5);\njulia> Aminus=compute_Mder(nep,\u03bb-\u03f5);\njulia> Aplus=compute_Mder(nep,\u03bb+\u03f5);\njulia> opnorm((Aplus-Aminus)/(2\u03f5)-compute_Mder(nep,\u03bb,1))\n1.990970375089371e-11\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPCore.compute_Mlincomb!\n \u2014 \nFunction\n.\n\n\ncompute_Mlincomb(nep::NEP,\u03bb::Number,V, a::Vector=ones(size(V,2)), startder=0)\ncompute_Mlincomb!(nep::NEP,\u03bb::Number,V, a::Vector=ones(size(V,2)), startder=0)\n\n\n\n\nComputes the linear combination of derivatives\n$\u03a3_i a_i M^{(i)}(\u03bb) v_i$ starting from derivative \nstartder\n. The function \ncompute_Mlincomb!\n does the same but may modify the \nV\n matrix/array.\n\n\nExample\n\n\nThis example shows that \ncompute_Mder\n gives a result consistent with \ncompute_Mlincomb\n. Note that \ncompute_Mlincomb\n is in general faster since no matrix needs to be constructed.\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> v=ones(size(nep,1)); \u03bb=-1+1im;\njulia> norm(compute_Mder(nep,\u03bb,1)*v-compute_Mlincomb(nep,\u03bb,hcat(v,v),[0,1]))\n1.0778315928076987e-15\n\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPCore.compute_MM\n \u2014 \nFunction\n.\n\n\ncompute_MM(nep::NEP,S,V)\n\n\n\n\nComputes the sum $\u03a3_i M_i V f_i(S)$ for a NEP, where $S$ and $V$ are matrices, and the NEP satisfies $M(\u03bb)=\u03a3_i M_i f_i(\u03bb)$.\n\n\nExample\n\n\nThis example shows that for diagonal \nS\n, the result of \ncompute_MM\n can also be computed with \ncompute_Mlincomb\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> D=diagm(0 => [1,2])\n2\u00d72 Array{Int64,2}:\n 1  0\n 0  2\njulia> V=ones(size(n,1),2);\njulia> W=compute_MM(nep,D,V);\njulia> norm(W[:,1]-compute_Mlincomb(nep,D[1,1],V[:,1]))\n1.1102230246251565e-16\njulia> norm(W[:,2]-compute_Mlincomb(nep,D[2,2],V[:,2]))\n0.0\n\n\n\n\nReference\n\n\nProperties of the quantity $\u03a3_i M_i V f_i(S)$ for non-polynomial nonlinear eigenvalue problems were extensively used in:\n\n\n\n\nD. Kressner A block Newton method for nonlinear eigenvalue problems, Numer. Math., 114 (2) (2009), pp. 355-372\n\n\nC. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne\n\n\n\n\nsource",
            "title": "NEP Types"
        },
        {
            "location": "/types/#neptypes",
            "text": "",
            "title": "NEPTypes"
        },
        {
            "location": "/types/#the-basic-type",
            "text": "The basic class is the abstract class  NEP  which represents a NEP. All other defined NEPs should inherit from  NEP , or from a more specialized version; see, e.g.,  ProjectableNEP  or  AbstractSPMF .  #  NonlinearEigenproblems.NEPCore.NEP  \u2014  Type .  abstract NEP  A  NEP  object represents a nonlinear eigenvalue problem. All NEPs should implement  size(nep::NEP,d)  and at least one of the following   M =  compute_Mder(nep::NEP,\u03bb::Number,i::Integer=0)  V =  compute_Mlincomb!(nep::NEP,\u03bb::Number,V::AbstractVecOrMat,a::Vector)  MM =  compute_MM(nep::NEP,S,V)   source  Below we list the most common types built-in to NEP-PACK, and further down how you can  access the NEP . However, the structure is made for extendability, and hence it is possible for you to extend with your own class of NEPs.",
            "title": "The basic type"
        },
        {
            "location": "/types/#spmf",
            "text": "One of the most common problem types is the  SPMF_NEP . SPMF is short for Sum of Products of Matrices and Functions and the NEP is described by  $$\nM(\u03bb) = \\sum_{i} A_i f_i(\u03bb).\n$$  #  NonlinearEigenproblems.NEPTypes.SPMF_NEP  \u2014  Type .  struct SPMF_NEP{T<:AbstractMatrix,Ftype}  <: AbstractSPMF{T}  An SPMF_NEP is a NEP defined by a Sum of Products of Matrices and Functions, i.e.,  $$\nM(\u03bb)=\u2211_i A_i f_i(\u03bb).\n$$  All of the matrices $A_0,...$ are of size $n\u00d7n$ and $f_i$ are a functions. The  functions $f_i$ must be defined for matrices in the standard matrix function sense.  source  In order to construct an  SPMF_NEP , we need to provide the matrices and the functions.  #  NonlinearEigenproblems.NEPTypes.SPMF_NEP  \u2014  Method .   SPMF_NEP(AA, fii, check_consistency, Schur_fact = false, align_sparsity_patterns = false, , Ftype)  Creates a  SPMF_NEP  consisting of matrices  AA  and functions  fii . The  SPMF_NEP  is defined by a sum of products of matrices and functions  $$\nM(\u03bb)=\u2211_i A_i f_i(\u03bb).\n$$  All of the matrices $A_0,...$ are of size $n\u00d7n$ and $f_i$ are a functions. The  functions $f_i$ must be defined for matrices in the standard matrix function sense.  Parameters   AA  is a  Vector  of matrices. The matrices have to be of the same type. If you need a NEP with different types you can use  SumNEP  to construct a sum of two  SPMF_NEP .  fii  is a  Vector  of functions. Each function takes one parameter  S . The functions must be available both as a scalar valid function and a matrix function. If  S  is a square matrix,  fii[k](S)  musst also be a square matrix. If  S  is a scalar  fii[k](S)  is a scalar.  check_consistency  (default  true ) determines if we should initiate by running tests to verify that the  fii  satisfies the conditions that every function is valid both for matrices and scalars. This is done by using  @code_typed  and the functions need to be type-stable in that sense.  align_sparsity_patterns  (default  false ) has effect only for sparse matrices ( SparseMatrixCSC ). If  align_sparsity_patterns=true  the  SparseMatrixCSC  matrices will be replaced by equivalent  SparseMatrixCSC  matrices where the  colptr  and  rowval  are identical. This increases the speed of some functions, e.g.,  compute_Mder . If  align_sparsity_patterns=true  the matrices in the NEP should be considered read only. If the sparsity patterns are completely or mostly distinct, it may be more efficient to set this flag to false.  Ftype  (default  ComplexF64 ) determines an underlying type of the functions. The output of any function should be \"smaller\" than the promoted type of the input and  Ftype . More precisely, if  F=fii[k] , then the type logic is as follows  eltype(F(\u03bb))=promote_type(eltype(\u03bb),Ftype) .  Schur_fact  (default  false ) determines if the  compute_MM  function should tridiagonalize the matrix before carrying out the computation. This can be faster for large matrices.   Example  julia> A0=[1 3; 4 5]; A1=[3 4; 5 6];\njulia> id_op=S -> one(S) # Note: We use one(S) to be valid both for matrices and scalars\njulia> exp_op=S -> exp(S)\njulia> nep=SPMF_NEP([A0,A1],[id_op,exp_op]);\njulia> compute_Mder(nep,1)-(A0+A1*exp(1))\n2\u00d72 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0  source",
            "title": "SPMF"
        },
        {
            "location": "/types/#abstract-spmfs",
            "text": "Many problems can be described in the class of SPMF. There might be more specialized and efficient implementations such as, e.g.  PEP ,  DEP  or  REP . However, on an abstract level it may still be important to recognize the similarities. Hence there is an abstract class  AbstractSPMF , which in itself inherits from  ProjectableNEP .  #  NonlinearEigenproblems.NEPTypes.AbstractSPMF  \u2014  Type .  abstract  AbstractSPMF <: ProjectableNEP  An AbstractSPMF is an abstract class representing NEPs which can be represented as a Sum of products of matrices and functions $M(\u03bb)=\u03a3_i A_i f_i(\u03bb)$, where i = 0,1,2,..., all of the matrices are of size n times n and f_i are functions.  Any AbstractSPMF has to have implementations of  get_Av()  and  get_fv()  which return the functions and matrices.  source  #  NonlinearEigenproblems.NEPTypes.get_Av  \u2014  Function .  get_Av(nep::AbstractSPMF)  Returns an array of matrices $A_i$ in the AbstractSPMF: $M(\u03bb)=\u03a3_i A_i f_i(\u03bb)$  source  #  NonlinearEigenproblems.NEPTypes.get_fv  \u2014  Function .  get_Av(nep::AbstractSPMF)  Returns an Array of functions (that can be evaluated both as scalar and matrix functions) $f_i$ in the AbstractSPMF: $M(\u03bb)=\u03a3_i A_i f_i(\u03bb)$  source",
            "title": "Abstract SPMFs"
        },
        {
            "location": "/types/#pep",
            "text": "The Polynomial Eigenvalue Problem is described by  $$\nM(\u03bb) = \\sum_{i} A_i \u03bb^i.\n$$  #  NonlinearEigenproblems.NEPTypes.PEP  \u2014  Type .  struct PEP <: AbstractSPMF  A polynomial eigenvalue problem (PEP) is defined by the sum the sum $\u03a3_i A_i \u03bb^i$, where i = 0,1,2,..., and  all of the matrices are of size n times n.  source  In order to construct a  PEP , we only need to provide the matrices.  #  NonlinearEigenproblems.NEPTypes.PEP  \u2014  Method .  PEP(AA::Array)  Creates a polynomial eigenvalue problem with monomial matrices specified in AA, which is an array of matrices.  julia> A0=[1 3; 4 5]; A1=A0.+one(2); A2=ones(2,2);\njulia> pep=PEP([A0,A1,A2])\njulia> compute_Mder(pep,3)-(A0+A1*3+A2*9)\n2\u00d72 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0  source",
            "title": "PEP"
        },
        {
            "location": "/types/#dep",
            "text": "The Delay Eigenvalue Problem is described by  $$\nM(\u03bb) = -\u03bbI + \\sum_{i} A_i e^{-\u03c4_i \u03bb}.\n$$  #  NonlinearEigenproblems.NEPTypes.DEP  \u2014  Type .  type DEP <: AbstractSPMF  A DEP (Delay Eigenvalue problem) is defined by the sum  $-\u03bbI + \u03a3_i A_i exp(-tau_i \u03bb)$ where all of the matrices are of size n times n.\nConstructor:  DEP(AA,tauv)  where  AA  is an array of the matrices $A_i$, and  tauv  is a vector of the values  $tau_i$.  Example:  julia> A0=randn(3,3); A1=randn(3,3);\njulia> tauv=[0,0.2] # Vector with delays\njulia> dep=DEP([A0,A1],tauv)\njulia> \u03bb=3.0;\njulia> M1=compute_Mder(dep,\u03bb)\njulia> M2=-\u03bb*I+A0+A1*exp(-tauv[2]*\u03bb)\njulia> norm(M1-M2)\n0.0  source",
            "title": "DEP"
        },
        {
            "location": "/types/#rep",
            "text": "The Rational Eigenvalue Problem is described by:  #  NonlinearEigenproblems.NEPTypes.REP  \u2014  Type .  struct REP <: AbstractSPMF  A REP represents a rational eigenvalue problem. The REP is defined by the sum $\u03a3_i A_i s_i(\u03bb)/q_i(\u03bb)$, where i = 0,1,2,..., all of the matrices are of size n times n and s i and q i are polynomials.  source  The constructor is called as:  #  NonlinearEigenproblems.NEPTypes.REP  \u2014  Method .  REP(A,poles)  Creates a rational eigenvalue problem. The constructor takes the matrices A_i and a sequence of poles as input (not complete).  Example  julia> A0=[1 2; 3 4]; A1=[3 4; 5 6];\njulia> nep=REP([A0,A1],[1,3]);\njulia> compute_Mder(nep,3)\n2\u00d72 Array{Float64,2}:\n NaN  NaN\n NaN  NaN  source",
            "title": "REP"
        },
        {
            "location": "/types/#sumnep",
            "text": "It is also possible to consider NEPs that are summs of other NEPs. For such situations there are SumNEPs. Specifically  GenericSumNEP  and  SPMFSumNEP . Both are constructed using the function  SumNEP .  #  NonlinearEigenproblems.NEPTypes.SumNEP  \u2014  Function .  SumNEP{nep1::NEP,nep2::NEP}\nSumNEP{nep1::AbstractSPMF,nep2::AbstractSPMF}  SumNEP is a function creating an object that corresponds to a sum of two NEPs, i.e., if nep is created by SumNEP it is defined by  $$\nM(\u03bb)=M_1(\u03bb)+M_2(\u03bb)\n$$  where M 1 and M 2 are defined by  nep1  and  nep2 .  Example:  julia> nep1=DEP([ones(3,3),randn(3,3)])\njulia> nep2=PEP([ones(3,3),randn(3,3),randn(3,3)])\njulia> sumnep=SumNEP(nep1,nep2);\njulia> s=3.0;\njulia> M=compute_Mder(sumnep,s);\n3\u00d73 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828\njulia> M1=compute_Mder(nep1,s);\njulia> M2=compute_Mder(nep2,s);\njulia> M1+M2  # Same as M\n3\u00d73 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828  See also:  SPMFSumNEP ,  GenericSumNEP  source  #  NonlinearEigenproblems.NEPTypes.GenericSumNEP  \u2014  Type .  struct GenericSumNEP{NEP1<:NEP,NEP2<:NEP}  <: NEP  See also:  SumNEP ,  SPMFSumNEP  source  #  NonlinearEigenproblems.NEPTypes.SPMFSumNEP  \u2014  Type .  struct SPMFSumNEP{NEP1<:AbstractSPMF,NEP2<:AbstractSPMF}  <: AbstractSPMF{AbstractMatrix}  See also:  SumNEP ,  GenericSumNEP  source",
            "title": "SumNEP"
        },
        {
            "location": "/types/#accessing-the-nep",
            "text": "The nonlinear eigenvalue problem is defined by the data stored in the NEP-class, and the NEP-solvers access the data mainly through three main functions,  compute_Mder   compute_Mlincomb  and  compute_MM .  #  NonlinearEigenproblems.NEPCore.compute_Mder  \u2014  Function .  compute_Mder(nep::NEP,\u03bb::Number [,i::Integer=0])  Computes the ith derivative of  nep  evaluated in  \u03bb .  Example  This example shows that  compute_Mder(nep,\u03bb,1)  gives the first derivative.  julia> nep=nep_gallery(\"dep0\");\njulia> \u03f5=1e-5;\njulia> Aminus=compute_Mder(nep,\u03bb-\u03f5);\njulia> Aminus=compute_Mder(nep,\u03bb-\u03f5);\njulia> Aplus=compute_Mder(nep,\u03bb+\u03f5);\njulia> opnorm((Aplus-Aminus)/(2\u03f5)-compute_Mder(nep,\u03bb,1))\n1.990970375089371e-11  source  #  NonlinearEigenproblems.NEPCore.compute_Mlincomb!  \u2014  Function .  compute_Mlincomb(nep::NEP,\u03bb::Number,V, a::Vector=ones(size(V,2)), startder=0)\ncompute_Mlincomb!(nep::NEP,\u03bb::Number,V, a::Vector=ones(size(V,2)), startder=0)  Computes the linear combination of derivatives\n$\u03a3_i a_i M^{(i)}(\u03bb) v_i$ starting from derivative  startder . The function  compute_Mlincomb!  does the same but may modify the  V  matrix/array.  Example  This example shows that  compute_Mder  gives a result consistent with  compute_Mlincomb . Note that  compute_Mlincomb  is in general faster since no matrix needs to be constructed.  julia> nep=nep_gallery(\"dep0\");\njulia> v=ones(size(nep,1)); \u03bb=-1+1im;\njulia> norm(compute_Mder(nep,\u03bb,1)*v-compute_Mlincomb(nep,\u03bb,hcat(v,v),[0,1]))\n1.0778315928076987e-15  source  #  NonlinearEigenproblems.NEPCore.compute_MM  \u2014  Function .  compute_MM(nep::NEP,S,V)  Computes the sum $\u03a3_i M_i V f_i(S)$ for a NEP, where $S$ and $V$ are matrices, and the NEP satisfies $M(\u03bb)=\u03a3_i M_i f_i(\u03bb)$.  Example  This example shows that for diagonal  S , the result of  compute_MM  can also be computed with  compute_Mlincomb  julia> nep=nep_gallery(\"dep0\");\njulia> D=diagm(0 => [1,2])\n2\u00d72 Array{Int64,2}:\n 1  0\n 0  2\njulia> V=ones(size(n,1),2);\njulia> W=compute_MM(nep,D,V);\njulia> norm(W[:,1]-compute_Mlincomb(nep,D[1,1],V[:,1]))\n1.1102230246251565e-16\njulia> norm(W[:,2]-compute_Mlincomb(nep,D[2,2],V[:,2]))\n0.0  Reference  Properties of the quantity $\u03a3_i M_i V f_i(S)$ for non-polynomial nonlinear eigenvalue problems were extensively used in:   D. Kressner A block Newton method for nonlinear eigenvalue problems, Numer. Math., 114 (2) (2009), pp. 355-372  C. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne   source",
            "title": "Accessing the NEP"
        },
        {
            "location": "/linsolvers/",
            "text": "LinSolvers\n\n\nMost NEP-algorithms need to solve the linear system associated with \nM(\u03bb)\n. We provide an interface to specify which solver to use or define your own solver.\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.LinSolver\n \u2014 \nType\n.\n\n\nabstract type LinSolver\n\n\n\n\nStructs inheriting from this type are able to solve linear systems associated with a NEP, for a specific \n\u03bb\n-value. The most common are direct solvers such as \nDefaultLinSolver\n, \nBackslashLinSolver\n and iterative solvers such as \nGMRESLinSolver\n.\n\n\nThe LinSolver objects are usually created by the NEP-algorithms through creator functions, which are passed as parameters.\n\n\nExample\n\n\nThe most common usecase is that you want to pass a \nlinsolvercreator\n-function as parameter to the NEP-algorithm. This example shows how you can solvers based on backslash or \nfactorize()\n. In the example, \nBackslashLinSolver\n does not exploit that the system matrix remains the same throughout the algorithm and is therefore slower.\n\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> using BenchmarkTools\njulia> v0=ones(size(nep,1));\njulia> @btime \u03bb,v=quasinewton(nep,\u03bb=-1,v=v0, linsolvercreator=default_linsolvercreator);\n  199.540 ms (4929 allocations: 59.83 MiB)\njulia> @btime \u03bb,v=quasinewton(nep,\u03bb=-1,v=v0, linsolvercreator=backslash_linsolvercreator);\n  1.632 s (6137 allocations: 702.85 MiB)\n\n\n\n\nExample\n\n\nThe \nLinSolver\ns are constructed for extendability. This example creates our own \nLinSolver\n which uses an explicit formula for the inverse if the NEP has dimension 2x2.\n\n\nCreate the types and a creator.\n\n\njulia> using LinearAlgebra\njulia> struct MyLinSolver <: LinSolver\n   M::Matrix{ComplexF64}\nend\njulia> function my_linsolvercreator(nep,\u03bb)\n   M=compute_Mder(nep,\u03bb);\n   return MyLinSolver(M);\nend\n\n\n\n\nExplicit import \nlin_solve\n to show how to solve a linear system.\n\n\njulia> import NonlinearEigenproblems.LinSolvers.lin_solve;\njulia> function lin_solve(solver::MyLinSolver,b::AbstractVecOrMat;tol=0)\n   M=solver.M;\n   invM=(1/(det(M)))*[M[2,2] -M[1,2];-M[2,1] M[1,1]]\n   return invM*b\nend\njulia> nep=SPMF_NEP([[1.0 3.0; 4.0 5.0], [2.0 1.0; -1 2.0]], [S->S^2,S->exp(S)])\njulia> \u03bb,v=quasinewton(nep,\u03bb=-1,v=[1;1],linsolvercreator=my_linsolvercreator);\n\n\n\n\nSee also: \nlin_solve\n, \nDefaultLinSolver\n, \ndefault_linsolvercreator\n, \nBackslashLinSolver\n, \nbackslash_linsolvercreator\n, \nGMRESLinSolver\n, \ngmres_linsolvercreator\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.lin_solve\n \u2014 \nFunction\n.\n\n\nlin_solve(solver::LinSolver, b::AbstractVecOrMat; tol=0)\n\n\n\n\nThis function solves the linear system represented in \nsolver::LinSolver\n with a right-hand side \nb\n. The \ntol\n kwarg is controlling how accurate the linear system needs to be solved. A NEP-algorithm will call this solver every time a linear system associated with \nM(\u03bb)\n needs to be solved.\n\n\nThis function must be overloaded if a user wants to define their own way of solving linear systems. See \nLinSolver\n for examples.\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.DefaultLinSolver\n \u2014 \nType\n.\n\n\nstruct DefaultLinSolver <: LinSolver\n\n\n\n\nThis represents the linear solver associated with julia \nfactorize()\n. See \nLinSolver\n and \ndefault_linsolvercreator\n for examples.\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.default_linsolvercreator\n \u2014 \nFunction\n.\n\n\ndefault_linsolvercreator(nep::NEP, \u03bb; umfpack_refinements = 2)\n\n\n\n\nCreate a linear solver of type \nDefaultLinSolver\n for the NEP evaluated in point \n\u03bb\n. For sparse matrices (the underlying solver is usually UMFPACK) the maximum number of iterative refinements can be changed to trade accuracy for performance with the parameter \numfpack_refinements\n. UMFPACK defaults to a maximum of 2 iterative refinements.\n\n\nFor examples see \nLinSolver\n.\n\n\nSee also: \nDefaultLinSolver\n.\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.BackslashLinSolver\n \u2014 \nType\n.\n\n\nstruct BackslashLinSolver <: LinSolver\n\n\n\n\nThis represents a linear solver corresponding to the backslash operator (no pre-factorization).\n\n\nSee also: \nLinSolver\n and \nbackslash_linsolvercreator\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.backslash_linsolvercreator\n \u2014 \nFunction\n.\n\n\nbackslash_linsolvercreator(nep::NEP, \u03bb)\n\n\n\n\nCreate a linear solver of type 'BackslashLinSolver' evaluated in \n\u03bb\n.\n\n\nSee also: \nLinSolver\n, \nBackslashLinSolver\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.GMRESLinSolver\n \u2014 \nType\n.\n\n\nstruct GMRESLinSolver <: LinSolver\n\n\n\n\nThis represents a solver done with the julia GMRES implementation.\n\n\nSee also: \nLinSolver\n, \ngmres_linsolvercreator\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.gmres_linsolvercreator\n \u2014 \nFunction\n.\n\n\ngmres_linsolvercreator(nep::NEP, \u03bb, kwargs=())\n\n\n\n\nCreate a linear solver of type 'GMRESLinSolver'. The kwargs are passed as parameter to Julia-built-in-GMRES.\n\n\nSee also: \nLinSolver\n, \nGMRESLinSolver\n\n\nsource\n\n\n\n\nEigSolvers\n\n\nSome NEP-algorithms need to solve an associated linear eigenvalue problem. associated with \nM(\u03bb)\n. You will likely only need the native eigensolvers in Julia. Nevertheless, we provide an interface to specify which solver to use or define your own solver.\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.EigSolver\n \u2014 \nType\n.\n\n\nabstract type EigSolver\n\n\n\n\nStructs inheriting from this type are able to solve linear eigenvalue problems arising in certain methods, such as, e.g., \nmslp\n, \nsgiter\n, and \npolyeig\n.\n\n\nThe \nEigSolver\n objects are passed as types to the NEP-algorithms, which uses it to dispatch the correct version of the function \neig_solve\n.\n\n\nExample\n\n\nThe most common usecase is that you do not want to specify anything in particular, since the \nDefaultEigSolver\n will use a dense or a sparse method depending on you problem. However, this example shows how you can force \nmslp\n to use the sparse solver.\n\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> \u03bb,v = mslp(nep, eigsolvertype=NativeEigSSolver);\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n1.0324139764567768e-15\n\n\n\n\nExample\n\n\nThe \nEigSolver\ns are constructed for extendability. As an illustartion this example creates a naive \nEigSolver\n which casts the problem to a standard linear eigenproblem and calls the built-in function to solve it.\n\n\nCreate the types and a creator.\n\n\njulia> struct MyEigSolver <: EigSolver\n   A\n   E\n   function MyEigSolver(A,E)\n      return new(A,E)\n   end\nend\n\njulia> import NonlinearEigenproblems.LinSolvers.eig_solve;\njulia> function eig_solve(solver::MyEigSolver;nev = 1, target = 0)\n   M = solver.E \\ solver.A\n   eig = eigen(M)\n   i = argmin(abs.(eig.values))\n   return eig.values[i], eig.vectors[:,i]\nend\njulia> nep=nep_gallery(\"dep0\", 50);\njulia> \u03bb,v = mslp(nep, eigsolvertype=MyEigSolver, tol=1e-5);\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n3.0777795031319117e-10\n\n\n\n\nSee also: \neig_solve\n, \nDefaultEigSolver\n, \nNativeEigSolver\n, \nNativeEigSSolver\n, \neig_solve\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.eig_solve\n \u2014 \nFunction\n.\n\n\neig_solve(solver::EigSolver; [nev,] [target,])\n\n\n\n\nThis function solves the linear eigenvalue problem represented in \nsolver::EigSolver\n. The \nnev\n kwarg is controlling the number of eigenvalues aimed for, and \ntarget\n specifies around which point the eigenvalues are computed. The former has a defalut value equalt to the seize of the problem, and the latter has a defalut value 0.\n\n\nThis function must be overloaded if a user wants to define their own way of solving linear eigenvalue problems. See \nEigSolver\n for examples.\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.DefaultEigSolver\n \u2014 \nType\n.\n\n\nmutable struct DefaultEigSolver <: EigSolver\n\n\n\n\nA linear eigenvalueproblem solver that calls checks for sparsity and accordingly assigns an appropriate solver.\n\n\nSee also: \nEigSolver\n, \neig_solve\n, \nNativeEigSolver\n, \nNativeEigSSolver\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.NativeEigSolver\n \u2014 \nType\n.\n\n\nmutable struct NativeEigSolver <: EigSolver\n\n\n\n\nA linear eigenvalueproblem solver that calls Julia's in-built eigen()\n\n\nConstructed as \nNativeEigSolver(A, [B,])\n, and solves the problem\n\n\n$$\nAx = \u03bbBx\n$$\n\n\nThe paramter \nB\n is optional an default is indentity, for which a standard linear eigenproblem is solved.\n\n\nSee also: \nEigSolver\n and \neig_solve\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.LinSolvers.NativeEigSSolver\n \u2014 \nType\n.\n\n\nmutable struct NativeEigSSolver <: EigSolver\n\n\n\n\nA linear eigenvalueproblem solver for large and sparse problems that calls Julia's in-built eigs()\n\n\nConstructed as \nNativeEigSSolver(A, [B,])\n, and solves the problem\n\n\n$$\nAx = \u03bbBx\n$$\n\n\nThe paramter \nB\n is optional an default is indentity, for which a standard linear eigenproblem is solved.\n\n\nSee also: \nEigSolver\n and \neig_solve\n\n\nsource",
            "title": "LinSolver"
        },
        {
            "location": "/linsolvers/#linsolvers",
            "text": "Most NEP-algorithms need to solve the linear system associated with  M(\u03bb) . We provide an interface to specify which solver to use or define your own solver.  #  NonlinearEigenproblems.LinSolvers.LinSolver  \u2014  Type .  abstract type LinSolver  Structs inheriting from this type are able to solve linear systems associated with a NEP, for a specific  \u03bb -value. The most common are direct solvers such as  DefaultLinSolver ,  BackslashLinSolver  and iterative solvers such as  GMRESLinSolver .  The LinSolver objects are usually created by the NEP-algorithms through creator functions, which are passed as parameters.  Example  The most common usecase is that you want to pass a  linsolvercreator -function as parameter to the NEP-algorithm. This example shows how you can solvers based on backslash or  factorize() . In the example,  BackslashLinSolver  does not exploit that the system matrix remains the same throughout the algorithm and is therefore slower.  julia> nep=nep_gallery(\"qdep0\");\njulia> using BenchmarkTools\njulia> v0=ones(size(nep,1));\njulia> @btime \u03bb,v=quasinewton(nep,\u03bb=-1,v=v0, linsolvercreator=default_linsolvercreator);\n  199.540 ms (4929 allocations: 59.83 MiB)\njulia> @btime \u03bb,v=quasinewton(nep,\u03bb=-1,v=v0, linsolvercreator=backslash_linsolvercreator);\n  1.632 s (6137 allocations: 702.85 MiB)  Example  The  LinSolver s are constructed for extendability. This example creates our own  LinSolver  which uses an explicit formula for the inverse if the NEP has dimension 2x2.  Create the types and a creator.  julia> using LinearAlgebra\njulia> struct MyLinSolver <: LinSolver\n   M::Matrix{ComplexF64}\nend\njulia> function my_linsolvercreator(nep,\u03bb)\n   M=compute_Mder(nep,\u03bb);\n   return MyLinSolver(M);\nend  Explicit import  lin_solve  to show how to solve a linear system.  julia> import NonlinearEigenproblems.LinSolvers.lin_solve;\njulia> function lin_solve(solver::MyLinSolver,b::AbstractVecOrMat;tol=0)\n   M=solver.M;\n   invM=(1/(det(M)))*[M[2,2] -M[1,2];-M[2,1] M[1,1]]\n   return invM*b\nend\njulia> nep=SPMF_NEP([[1.0 3.0; 4.0 5.0], [2.0 1.0; -1 2.0]], [S->S^2,S->exp(S)])\njulia> \u03bb,v=quasinewton(nep,\u03bb=-1,v=[1;1],linsolvercreator=my_linsolvercreator);  See also:  lin_solve ,  DefaultLinSolver ,  default_linsolvercreator ,  BackslashLinSolver ,  backslash_linsolvercreator ,  GMRESLinSolver ,  gmres_linsolvercreator  source  #  NonlinearEigenproblems.LinSolvers.lin_solve  \u2014  Function .  lin_solve(solver::LinSolver, b::AbstractVecOrMat; tol=0)  This function solves the linear system represented in  solver::LinSolver  with a right-hand side  b . The  tol  kwarg is controlling how accurate the linear system needs to be solved. A NEP-algorithm will call this solver every time a linear system associated with  M(\u03bb)  needs to be solved.  This function must be overloaded if a user wants to define their own way of solving linear systems. See  LinSolver  for examples.  source  #  NonlinearEigenproblems.LinSolvers.DefaultLinSolver  \u2014  Type .  struct DefaultLinSolver <: LinSolver  This represents the linear solver associated with julia  factorize() . See  LinSolver  and  default_linsolvercreator  for examples.  source  #  NonlinearEigenproblems.LinSolvers.default_linsolvercreator  \u2014  Function .  default_linsolvercreator(nep::NEP, \u03bb; umfpack_refinements = 2)  Create a linear solver of type  DefaultLinSolver  for the NEP evaluated in point  \u03bb . For sparse matrices (the underlying solver is usually UMFPACK) the maximum number of iterative refinements can be changed to trade accuracy for performance with the parameter  umfpack_refinements . UMFPACK defaults to a maximum of 2 iterative refinements.  For examples see  LinSolver .  See also:  DefaultLinSolver .  source  #  NonlinearEigenproblems.LinSolvers.BackslashLinSolver  \u2014  Type .  struct BackslashLinSolver <: LinSolver  This represents a linear solver corresponding to the backslash operator (no pre-factorization).  See also:  LinSolver  and  backslash_linsolvercreator  source  #  NonlinearEigenproblems.LinSolvers.backslash_linsolvercreator  \u2014  Function .  backslash_linsolvercreator(nep::NEP, \u03bb)  Create a linear solver of type 'BackslashLinSolver' evaluated in  \u03bb .  See also:  LinSolver ,  BackslashLinSolver  source  #  NonlinearEigenproblems.LinSolvers.GMRESLinSolver  \u2014  Type .  struct GMRESLinSolver <: LinSolver  This represents a solver done with the julia GMRES implementation.  See also:  LinSolver ,  gmres_linsolvercreator  source  #  NonlinearEigenproblems.LinSolvers.gmres_linsolvercreator  \u2014  Function .  gmres_linsolvercreator(nep::NEP, \u03bb, kwargs=())  Create a linear solver of type 'GMRESLinSolver'. The kwargs are passed as parameter to Julia-built-in-GMRES.  See also:  LinSolver ,  GMRESLinSolver  source",
            "title": "LinSolvers"
        },
        {
            "location": "/linsolvers/#eigsolvers",
            "text": "Some NEP-algorithms need to solve an associated linear eigenvalue problem. associated with  M(\u03bb) . You will likely only need the native eigensolvers in Julia. Nevertheless, we provide an interface to specify which solver to use or define your own solver.  #  NonlinearEigenproblems.LinSolvers.EigSolver  \u2014  Type .  abstract type EigSolver  Structs inheriting from this type are able to solve linear eigenvalue problems arising in certain methods, such as, e.g.,  mslp ,  sgiter , and  polyeig .  The  EigSolver  objects are passed as types to the NEP-algorithms, which uses it to dispatch the correct version of the function  eig_solve .  Example  The most common usecase is that you do not want to specify anything in particular, since the  DefaultEigSolver  will use a dense or a sparse method depending on you problem. However, this example shows how you can force  mslp  to use the sparse solver.  julia> nep=nep_gallery(\"qdep0\");\njulia> \u03bb,v = mslp(nep, eigsolvertype=NativeEigSSolver);\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n1.0324139764567768e-15  Example  The  EigSolver s are constructed for extendability. As an illustartion this example creates a naive  EigSolver  which casts the problem to a standard linear eigenproblem and calls the built-in function to solve it.  Create the types and a creator.  julia> struct MyEigSolver <: EigSolver\n   A\n   E\n   function MyEigSolver(A,E)\n      return new(A,E)\n   end\nend\n\njulia> import NonlinearEigenproblems.LinSolvers.eig_solve;\njulia> function eig_solve(solver::MyEigSolver;nev = 1, target = 0)\n   M = solver.E \\ solver.A\n   eig = eigen(M)\n   i = argmin(abs.(eig.values))\n   return eig.values[i], eig.vectors[:,i]\nend\njulia> nep=nep_gallery(\"dep0\", 50);\njulia> \u03bb,v = mslp(nep, eigsolvertype=MyEigSolver, tol=1e-5);\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n3.0777795031319117e-10  See also:  eig_solve ,  DefaultEigSolver ,  NativeEigSolver ,  NativeEigSSolver ,  eig_solve  source  #  NonlinearEigenproblems.LinSolvers.eig_solve  \u2014  Function .  eig_solve(solver::EigSolver; [nev,] [target,])  This function solves the linear eigenvalue problem represented in  solver::EigSolver . The  nev  kwarg is controlling the number of eigenvalues aimed for, and  target  specifies around which point the eigenvalues are computed. The former has a defalut value equalt to the seize of the problem, and the latter has a defalut value 0.  This function must be overloaded if a user wants to define their own way of solving linear eigenvalue problems. See  EigSolver  for examples.  source  #  NonlinearEigenproblems.LinSolvers.DefaultEigSolver  \u2014  Type .  mutable struct DefaultEigSolver <: EigSolver  A linear eigenvalueproblem solver that calls checks for sparsity and accordingly assigns an appropriate solver.  See also:  EigSolver ,  eig_solve ,  NativeEigSolver ,  NativeEigSSolver  source  #  NonlinearEigenproblems.LinSolvers.NativeEigSolver  \u2014  Type .  mutable struct NativeEigSolver <: EigSolver  A linear eigenvalueproblem solver that calls Julia's in-built eigen()  Constructed as  NativeEigSolver(A, [B,]) , and solves the problem  $$\nAx = \u03bbBx\n$$  The paramter  B  is optional an default is indentity, for which a standard linear eigenproblem is solved.  See also:  EigSolver  and  eig_solve  source  #  NonlinearEigenproblems.LinSolvers.NativeEigSSolver  \u2014  Type .  mutable struct NativeEigSSolver <: EigSolver  A linear eigenvalueproblem solver for large and sparse problems that calls Julia's in-built eigs()  Constructed as  NativeEigSSolver(A, [B,]) , and solves the problem  $$\nAx = \u03bbBx\n$$  The paramter  B  is optional an default is indentity, for which a standard linear eigenproblem is solved.  See also:  EigSolver  and  eig_solve  source",
            "title": "EigSolvers"
        },
        {
            "location": "/transformations/",
            "text": "Transforming NEPs\n\n\nThere are various ways to transform NEPs into other NEPs. The simplest example is the function \nshift_and_scale()\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.shift_and_scale\n \u2014 \nFunction\n.\n\n\nshift_and_scale(orgnep::NEP;shift=0,scale=1)\n\n\n\n\nTransforms the orgnep by defining a new NEP from the relation T(\u03bb)=M(scale * \u03bb+shift) where M is the orgnep. This function tries  to preserve the NEP type, e.g., a shift\nand\nscale operation on an SPMF-object, return an SPMF object. If it cannot preserve the type, it will return a nep of the struct \nShiftScaledNEP\n.\n\n\nExample\n\n\njulia> nep0=nep_gallery(\"pep0\")\njulia> \u03c3=3; \u03b1=10;\njulia> nep1=shift_and_scale(nep0,shift=\u03c3,scale=\u03b1)\njulia> opnorm(compute_Mder(nep0,\u03b1*(4+4im)+\u03c3)-compute_Mder(nep1,4+4im))\n8.875435870738592e-12\n\n\n\n\nsource\n\n\nSimilarly \nmobius_transform()\n is more general than \nshift_and_scale\n which transform the problem using a M\u00f6bius transformation. The function \ntaylor_exp\n create new PEP by doing truncating a Taylor expansion.\n\n\n\n\nProjection\n\n\nSeveral methods for NEPs are based on forming a smaller NEP, which we will refer to as a projection:\n\n\n$$\nN(\u03bb)=W^HM(\u03bb)V,\n$$\n\n\nwhere $V,W\\in\\mathbb{C}^{n\\times p}$ and the corresponding projected problem\n\n\n$$\nN(\u03bb)u=0.\n$$\n\n\n\n\nTypes\n\n\nNEPs for which this projection can be computed inherit from \nProjectableNEP\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.ProjectableNEP\n \u2014 \nType\n.\n\n\nabstract ProjectableNEP <: NEP\n\n\n\n\nA ProjectableNEP is a NEP which can be projected, i.e., one can construct the problem $W'*M(\u03bb)Vw=0$ with the \nProj_NEP\n. A NEP which is of this must have the function \ncreate_proj_NEP(orgnep::ProjectableNEP)\n implemented. This function must return a \nProj_NEP\n.\n\n\nSee also: \nset_projectmatrices!\n.\n\n\nExample:\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> typeof(nep)\nDEP{Float64,Array{Float64,2}}\njulia> isa(nep,ProjectableNEP)\ntrue\njulia> projnep=create_proj_NEP(nep);\njulia> e1 = Matrix(1.0*I,size(nep,1),1);\njulia> set_projectmatrices!(projnep,e1,e1);\njulia> compute_Mder(nep,3.0)[1,1]\n-2.315345215259418\njulia> compute_Mder(projnep,3.0)\n1\u00d71 Array{Float64,2}:\n -2.315345215259418\n\n\n\n\nsource\n\n\nThe result of the projection is represented in a \nProj_NEP\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.Proj_NEP\n \u2014 \nType\n.\n\n\nabstract type Proj_NEP <: NEP\n\n\n\n\nProj_NEP\n represents a projected NEP. The projection is defined as the NEP\n\n\n$$\nN(\u03bb)=W^HM(\u03bb)V\n$$\n\n\nwhere $M(\u03bb)$ is a base NEP and \nW\n and \nV\n rectangular matrices representing a basis of the projection spaces. Instances are created with \ncreate_proj_NEP\n. See \ncreate_proj_NEP\n for examples.\n\n\nAny \nProj_NEP\n needs to implement two functions to manipulate the projection:\n\n\n\n\nset_projectmatrices!\n: Set matrices \nW\n and \nV\n\n\nexpand_projectmatrices!\n: Effectively expand the matrices \nW\n and \nV\n with one column.\n\n\n\n\nsource\n\n\nOne explicit instance is the \nProj_SPMF_NEP\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.Proj_SPMF_NEP\n \u2014 \nType\n.\n\n\nstruct Proj_SPMF_NEP <: Proj_NEP\n\n\n\n\nThis type represents the (generic) way to project NEPs which are \nAbstractSPMF\n. See examples in \ncreate_proj_NEP\n.\n\n\nsource\n\n\n\n\nAssociated functions\n\n\nYou can create a projected NEP with \ncreate_proj_NEP\n:\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.create_proj_NEP\n \u2014 \nFunction\n.\n\n\npnep=create_proj_NEP(orgnep::ProjectableNEP[,maxsize [,T]])\n\n\n\n\nCreate a NEP representing a projected problem $N(\u03bb)=W^HM(\u03bb)V$,  where the  base NEP is represented by \norgnep\n. The optional parameter \nmaxsize::Int\n determines how large the projected problem can be and \nT\n is the Number type used for the projection matrices (default \nComplexF64\n). These are needed for memory preallocation reasons. Use \nset_projectmatrices!\n and \nexpand_projectmatrices!\n  to specify projection matrices $V$ and $W$.\n\n\nExample:\n\n\nThe following example illustrates that a projection of a \nNEP\n is also a \nNEP\n and we can for instance call \ncompute_Mder\n on it:\n\n\njulia> nep=nep_gallery(\"pep0\")\njulia> V=Matrix(1.0*I,size(nep,1),2);\njulia> W=Matrix(1.0*I,size(nep,1),2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2\u00d72 Array{Complex{Float64},2}:\n -2.03662+0.0im   13.9777+0.0im\n -1.35069+0.0im  -13.0975+0.0im\njulia> W'*compute_Mder(nep,3.0)*V  # Gives the same result\n2\u00d72 Array{Float64,2}:\n -2.03662   13.9777\n -1.35069  -13.0975\n\n\n\n\nIf you know that you will only use real projection matrices, you can specify this in at the creation:\n\n\njulia> pnep=create_proj_NEP(nep,2,Float64);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2\u00d72 Array{Float64,2}:\n -2.03662   13.9777\n -1.35069  -13.0975\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.set_projectmatrices!\n \u2014 \nFunction\n.\n\n\nset_projectmatrices!(pnep::Proj_NEP,W,V)\n\n\n\n\nSet the projection matrices for the NEP to W and V, i.e., corresponding the NEP: $N(\u03bb)=W^HM(\u03bb)V$. See also \ncreate_proj_NEP\n.\n\n\nExample\n\n\nThis illustrates if \nW\n and \nV\n are vectors of ones, the projected problem becomes the sum of the rows and columns of the original NEP.\n\n\njulia> nep=nep_gallery(\"pep0\")\njulia> pnep=create_proj_NEP(nep);\njulia> V=ones(200,1);  W=ones(200,1);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n1\u00d71 Array{Complex{Float64},2}:\n 48.948104019482756 + 0.0im\njulia> sum(compute_Mder(nep,0),dims=[1,2])\n1\u00d71 Array{Float64,2}:\n 48.948104019482955\n\n\n\n\nsource\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.expand_projectmatrices!\n \u2014 \nFunction\n.\n\n\nexpand_projectmatrices!(nep::Proj_SPMF_NEP, Wnew, Vnew)\n\n\n\n\nThe projected NEP is updated by adding the last column of \nWnew\n and \nVnew\n to the basis. Note that \nWnew\n and \nVnew\n contain also the \"old\" basis vectors. See also \ncreate_proj_NEP\n\n\nExample:\n\n\nIn the following example you see that the expanded projected problem has one row and column more, and the leading subblock is the same as the smaller projected NEP.\n\n\njulia> nep=nep_gallery(\"pep0\"); n=size(nep,1);\njulia> V=Matrix(1.0*I,n,2); W=Matrix(1.0*I,n,2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n2\u00d72 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im\n 0.828413+0.0im  0.0646768+0.0im\njulia> Vnew=[V ones(n)]\njulia> Wnew=[W ones(n)]\njulia> expand_projectmatrices!(pnep,Wnew,Vnew);\njulia> compute_Mder(pnep,0)\n3\u00d73 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im  -12.1418+0.0im\n 0.828413+0.0im  0.0646768+0.0im   16.3126+0.0im\n -17.1619+0.0im   -10.1628+0.0im   48.9481+0.0im\n\n\n\n\nsource\n\n\n\n\nDeflation\n\n\nDue to structure of the representation of NEPs in NEP-PACK it is possible to do deflation, by transformation of the NEP-object. The deflation is based on theory provided in Effenbergers thesis and the main function consists of \neffenberger_deflation\n.\n\n\n#\n\n\nNonlinearEigenproblems.NEPTypes.effenberger_deflation\n \u2014 \nFunction\n.\n\n\neffenberger_deflation(nep::NEP,S0,V0)\n\n\n\n\nThis function creates a deflated NEP based on (S0,V0), which are assumed to an invariant pair of \nnep\n. Effectively, the function should return a NEP which has the same solutions as orgnep, except those corresponding to (S0,V0).\n\n\nExample:\n\n\njulia> nep=nep_gallery(\"dep0\");\njulia> (\u03bb,v)=newton(nep);\njulia> n=size(nep,1);\njulia> S0=reshape([\u03bb],1,1);\njulia> V0=reshape(v,n,1);\njulia> dnep=effenberger_deflation(nep,S0,V0)\njulia> (\u03bb2,v2)=augnewton(dnep);  # this converges to different eigval\njulia> minimum(svdvals(compute_Mder(nep,\u03bb2)))\n9.323003321058995e-17\n\n\n\n\nReferences\n\n\n\n\nC. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne\n\n\n\n\nsource",
            "title": "NEP transformations"
        },
        {
            "location": "/transformations/#transforming-neps",
            "text": "There are various ways to transform NEPs into other NEPs. The simplest example is the function  shift_and_scale() .  #  NonlinearEigenproblems.NEPTypes.shift_and_scale  \u2014  Function .  shift_and_scale(orgnep::NEP;shift=0,scale=1)  Transforms the orgnep by defining a new NEP from the relation T(\u03bb)=M(scale * \u03bb+shift) where M is the orgnep. This function tries  to preserve the NEP type, e.g., a shift and scale operation on an SPMF-object, return an SPMF object. If it cannot preserve the type, it will return a nep of the struct  ShiftScaledNEP .  Example  julia> nep0=nep_gallery(\"pep0\")\njulia> \u03c3=3; \u03b1=10;\njulia> nep1=shift_and_scale(nep0,shift=\u03c3,scale=\u03b1)\njulia> opnorm(compute_Mder(nep0,\u03b1*(4+4im)+\u03c3)-compute_Mder(nep1,4+4im))\n8.875435870738592e-12  source  Similarly  mobius_transform()  is more general than  shift_and_scale  which transform the problem using a M\u00f6bius transformation. The function  taylor_exp  create new PEP by doing truncating a Taylor expansion.",
            "title": "Transforming NEPs"
        },
        {
            "location": "/transformations/#projection",
            "text": "Several methods for NEPs are based on forming a smaller NEP, which we will refer to as a projection:  $$\nN(\u03bb)=W^HM(\u03bb)V,\n$$  where $V,W\\in\\mathbb{C}^{n\\times p}$ and the corresponding projected problem  $$\nN(\u03bb)u=0.\n$$",
            "title": "Projection"
        },
        {
            "location": "/transformations/#types",
            "text": "NEPs for which this projection can be computed inherit from  ProjectableNEP .  #  NonlinearEigenproblems.NEPTypes.ProjectableNEP  \u2014  Type .  abstract ProjectableNEP <: NEP  A ProjectableNEP is a NEP which can be projected, i.e., one can construct the problem $W'*M(\u03bb)Vw=0$ with the  Proj_NEP . A NEP which is of this must have the function  create_proj_NEP(orgnep::ProjectableNEP)  implemented. This function must return a  Proj_NEP .  See also:  set_projectmatrices! .  Example:  julia> nep=nep_gallery(\"dep0\");\njulia> typeof(nep)\nDEP{Float64,Array{Float64,2}}\njulia> isa(nep,ProjectableNEP)\ntrue\njulia> projnep=create_proj_NEP(nep);\njulia> e1 = Matrix(1.0*I,size(nep,1),1);\njulia> set_projectmatrices!(projnep,e1,e1);\njulia> compute_Mder(nep,3.0)[1,1]\n-2.315345215259418\njulia> compute_Mder(projnep,3.0)\n1\u00d71 Array{Float64,2}:\n -2.315345215259418  source  The result of the projection is represented in a  Proj_NEP .  #  NonlinearEigenproblems.NEPTypes.Proj_NEP  \u2014  Type .  abstract type Proj_NEP <: NEP  Proj_NEP  represents a projected NEP. The projection is defined as the NEP  $$\nN(\u03bb)=W^HM(\u03bb)V\n$$  where $M(\u03bb)$ is a base NEP and  W  and  V  rectangular matrices representing a basis of the projection spaces. Instances are created with  create_proj_NEP . See  create_proj_NEP  for examples.  Any  Proj_NEP  needs to implement two functions to manipulate the projection:   set_projectmatrices! : Set matrices  W  and  V  expand_projectmatrices! : Effectively expand the matrices  W  and  V  with one column.   source  One explicit instance is the  Proj_SPMF_NEP .  #  NonlinearEigenproblems.NEPTypes.Proj_SPMF_NEP  \u2014  Type .  struct Proj_SPMF_NEP <: Proj_NEP  This type represents the (generic) way to project NEPs which are  AbstractSPMF . See examples in  create_proj_NEP .  source",
            "title": "Types"
        },
        {
            "location": "/transformations/#associated-functions",
            "text": "You can create a projected NEP with  create_proj_NEP :  #  NonlinearEigenproblems.NEPTypes.create_proj_NEP  \u2014  Function .  pnep=create_proj_NEP(orgnep::ProjectableNEP[,maxsize [,T]])  Create a NEP representing a projected problem $N(\u03bb)=W^HM(\u03bb)V$,  where the  base NEP is represented by  orgnep . The optional parameter  maxsize::Int  determines how large the projected problem can be and  T  is the Number type used for the projection matrices (default  ComplexF64 ). These are needed for memory preallocation reasons. Use  set_projectmatrices!  and  expand_projectmatrices!   to specify projection matrices $V$ and $W$.  Example:  The following example illustrates that a projection of a  NEP  is also a  NEP  and we can for instance call  compute_Mder  on it:  julia> nep=nep_gallery(\"pep0\")\njulia> V=Matrix(1.0*I,size(nep,1),2);\njulia> W=Matrix(1.0*I,size(nep,1),2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2\u00d72 Array{Complex{Float64},2}:\n -2.03662+0.0im   13.9777+0.0im\n -1.35069+0.0im  -13.0975+0.0im\njulia> W'*compute_Mder(nep,3.0)*V  # Gives the same result\n2\u00d72 Array{Float64,2}:\n -2.03662   13.9777\n -1.35069  -13.0975  If you know that you will only use real projection matrices, you can specify this in at the creation:  julia> pnep=create_proj_NEP(nep,2,Float64);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2\u00d72 Array{Float64,2}:\n -2.03662   13.9777\n -1.35069  -13.0975  source  #  NonlinearEigenproblems.NEPTypes.set_projectmatrices!  \u2014  Function .  set_projectmatrices!(pnep::Proj_NEP,W,V)  Set the projection matrices for the NEP to W and V, i.e., corresponding the NEP: $N(\u03bb)=W^HM(\u03bb)V$. See also  create_proj_NEP .  Example  This illustrates if  W  and  V  are vectors of ones, the projected problem becomes the sum of the rows and columns of the original NEP.  julia> nep=nep_gallery(\"pep0\")\njulia> pnep=create_proj_NEP(nep);\njulia> V=ones(200,1);  W=ones(200,1);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n1\u00d71 Array{Complex{Float64},2}:\n 48.948104019482756 + 0.0im\njulia> sum(compute_Mder(nep,0),dims=[1,2])\n1\u00d71 Array{Float64,2}:\n 48.948104019482955  source  #  NonlinearEigenproblems.NEPTypes.expand_projectmatrices!  \u2014  Function .  expand_projectmatrices!(nep::Proj_SPMF_NEP, Wnew, Vnew)  The projected NEP is updated by adding the last column of  Wnew  and  Vnew  to the basis. Note that  Wnew  and  Vnew  contain also the \"old\" basis vectors. See also  create_proj_NEP  Example:  In the following example you see that the expanded projected problem has one row and column more, and the leading subblock is the same as the smaller projected NEP.  julia> nep=nep_gallery(\"pep0\"); n=size(nep,1);\njulia> V=Matrix(1.0*I,n,2); W=Matrix(1.0*I,n,2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n2\u00d72 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im\n 0.828413+0.0im  0.0646768+0.0im\njulia> Vnew=[V ones(n)]\njulia> Wnew=[W ones(n)]\njulia> expand_projectmatrices!(pnep,Wnew,Vnew);\njulia> compute_Mder(pnep,0)\n3\u00d73 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im  -12.1418+0.0im\n 0.828413+0.0im  0.0646768+0.0im   16.3126+0.0im\n -17.1619+0.0im   -10.1628+0.0im   48.9481+0.0im  source",
            "title": "Associated functions"
        },
        {
            "location": "/transformations/#deflation",
            "text": "Due to structure of the representation of NEPs in NEP-PACK it is possible to do deflation, by transformation of the NEP-object. The deflation is based on theory provided in Effenbergers thesis and the main function consists of  effenberger_deflation .  #  NonlinearEigenproblems.NEPTypes.effenberger_deflation  \u2014  Function .  effenberger_deflation(nep::NEP,S0,V0)  This function creates a deflated NEP based on (S0,V0), which are assumed to an invariant pair of  nep . Effectively, the function should return a NEP which has the same solutions as orgnep, except those corresponding to (S0,V0).  Example:  julia> nep=nep_gallery(\"dep0\");\njulia> (\u03bb,v)=newton(nep);\njulia> n=size(nep,1);\njulia> S0=reshape([\u03bb],1,1);\njulia> V0=reshape(v,n,1);\njulia> dnep=effenberger_deflation(nep,S0,V0)\njulia> (\u03bb2,v2)=augnewton(dnep);  # this converges to different eigval\njulia> minimum(svdvals(compute_Mder(nep,\u03bb2)))\n9.323003321058995e-17  References   C. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne   source",
            "title": "Deflation"
        },
        {
            "location": "/gallery/",
            "text": "The Gallery function\n\n\nA large number of examples are provided in the \nnep_gallery\n.\n\n\njulia> using Gallery\njulia> nep=nep_gallery(\"dep0\")\njulia> \u03bb,v=newton(nep)\n(-0.3587189459686265 + 0.0im, Complex{Float64}[0.284742+0.0im, -0.143316+0.0im, 0.278378+0.0im, -0.5009+0.0im, -0.613634+0.0im])\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n4.718447854656915e-16\n\n\n\n\n#\n\n\nNonlinearEigenproblems.Gallery.nep_gallery\n \u2014 \nFunction\n.\n\n\n nep=nep_gallery(name)\n nep=nep_gallery(name,params)\n nep=nep_gallery(name,params;kwargs)\n\n\n\n\nCollection of nonlinear eigenvalue problems. Returns a NEP object from a gallery of examples of nonlinear eigenvalue problems. The parameter \nname\n decides which NEP.\n\n\nSupported problems:\n\n\nThe following list describes the NEP with a certain \nname\n and the associated parameters (\nparams\n) and keyword arguments (\nkwargs\n), if any.\n\n\n\n\ndep0\n   Create a random delay eiganvalue problem with one delay tau = 1.\n      One optional \nparams\n determining the size (default = 5)\n\n\ndep0_sparse\n\n      Create a random delay eiganvalue problem with sparse matrices and one delay tau = 1.\n      Two optional \nparams\n determining the size (default = 5) and the fill (default = 0.25)\n\n\ndep0_tridiag\n\n      Create a random delay eiganvalue problem with sparse tridiaognal matrices and one delay tau = 1.\n      One optional \nparams\n determining the size (default = 100)\n\n\ndep_symm_double\n\n      Create delay eiganvalue problem with double eigenvalues and sparse symmetric matrices and one delay tau = 1.\n      Examle from H. Voss and M. M. Betcke, Restarting iterative projection methods for Hermitian nonlinear eigenvalue problems with minmax property, Numer. Math., 2017\n      One optional \nparams\n determining the size (default = 100)\n\n\ndep_double\n\n      Create problem with a double non-semisimple eigenvalue in \u03bb=3\u03c0i.\n      Example from E. Jarlebring, Convergence factors of Newton methods for nonlinear eigenvalue problems, LAA, 2012\n\n\ndep1\n\n      A delay eigenvalue problem with one eigenvalue equal to one.\n\n\npep0\n\n      Create a random polynomial eigenvalue problem.\n      One optional \nparams\n determining the size (default = 200)\n\n\npep0_sym\n\n      Creates a random symmetric polynomial eigenvalue problem.\n      One optional \nparams\n determining the size (default = 200)\n\n\npep0_sparse\n\n      Creates a random polynomial eigenvalue problem with sparse matrices.\n      Two optional \nparams\n determining the size (default = 200) and the fill (default = 0.03)\n\n\nreal_quadratic\n\n      Creates a quadratic problem with real eigenvalues.\n            Four smallest eigenvalues of the problem:\n            -2051.741417993845\n            -182.101627437811\n            -39.344930222838\n            -4.039879577113\n\n\ndep_distributed\n\n      Creates the NEP associated with example in E. Jarlebring and W. Michiels and K. Meerbergen,   The infinite Arnoldi method and an application to time-delay systems with distributed delays,   Delay Systems - Methods, Applications and New Trends, 2012.\n           Some correct eigenvalues:        \n-0.400236388049641 + 0.970633098237807i\n,\n           \n-0.400236388049641 - 0.970633098237807i\n,\n           \n2.726146249832675 + 0.000000000000000i\n,\n           \n-1.955643591177653 + 3.364550574688863i\n,\n           \n-1.955643591177653 - 3.364550574688863i\n,\n           \n4.493937056300693 + 0.000000000000000i\n,\n           \n-1.631513006819252 + 4.555484848248613i\n,\n           \n-1.631513006819252 - 4.555484848248613i\n,\n           \n-1.677320660400946 + 7.496870451838560i\n,\n           \n-1.677320660400946 - 7.496870451838560i\n\n\nqdep0\n \n      Quadratic delay eigenvalue problem in S. W. Gaaf and E. Jarlebring, The infinite Bi-Lanczos method for   nonlinear eigenvalue problems, SIAM J. Sci. Comput., 2017\n\n\nqdep1\n \n      Quadratic delay eigenvalue problem in E. Jarlebring and W. Michiels and K. Meerbergen,   A linear eigenvalue algorithm for the  nonlinear eigenvalue problem, Numer. Math., 2011\n\n\nqep_fixed_eig\n\n      A quadratic eigenvalue problem with chosen eigenvalues.\n      Two optional \nparams\n determining the size (default = 5)   and a vector containing the eigenvalues (default = randn)\n\n\nneuron0\n\n      A DEP that stems from L. P. Shayer and S. A. Campbell, Stability, bifurcation and multistability   in a system of two coupled neurons with multiple time delays,   SIAM J. Applied Mathematics, 2000. It is also a benchmark example in DDE-BIFTOOL\n\n\nbeam\n\n      The DEP modelling a beam with delayed stabilizing feedback described in R. Van Beeumen, E. Jarlebring, and W. Michiels,   A rank-exploiting infinite Arnoldi algorithm for nonlinear eigenvalue problems, 2016.\n      The A1-term has rank one.\n      One optional \nparams\n which is the size of the matrix (defalut = 100)\n\n\n\n\nsine\n \n      The NEP formed by the sum of a polynomial and a sine-function in \"A rank-exploiting infinite Arnoldi   algorithm for nonlinear eigenvalue problems\", R. Van Beeumen, E. Jarlebring and W. Michiels, 2016. The sine-term has rank one.\n\n\nThe MATLAB-package \"NLEVP: A Collection of Nonlinear Eigenvalue Problems, ACM Transactions on Mathematical Software 39(2), January 2011,   T. Betcke, N. J. Higham, V. Mehrmann, Ch. Schr\u00f6der, F. Tisseur\" provides a number of benchmark problems for NEPs.   These are available in NEP-PACK in two different ways. We have native implementations of some problems (referred to as \nnlevp_native_\n)   and the separate \nGalleryNLEVP\n. The native implementation is preferred since the \nGalleryNLEVP\n   interfaces with MATLAB and is therefore considerably slower.\n\n\n\n\n\n\nnlevp_native_gun\n\n      The benchmark problem from the NLEVP-collection called \"gun\", represented in the native NEP-PACK format.   B.-S. Liao, Z. Bai, L.-Q. Lee, and K. Ko. Nonlinear Rayleigh-Ritz iterative method for solving large scale   nonlinear eigenvalue problems.  Taiwan. Journal of Mathematics, 14(3):869\u2013883, 2010\n\n\n\n\n\n\nnlevp_native_cd_player\n\n      The benchmark problem from the NLEVP-collection called \"cd_player\", represented in the native NEP-PACK format.   Y. Chahlaoui, and P. M. Van Dooren, Benchmark examples for model reduction of linear time-   invariant dynamical systems. In Dimension Reduction of Large-Scale Systems, P. Benner, V. Mehrmann,   and D. C. Sorensen, Eds. Lecture Notes in Computational Science and Engineering Series, vol. 45.   Springer-Verlag, Berlin, 380\u2013392, 2005.\n      and\n      P. M. R. Wortelboer, M. Steinbuch, and  O. H. Bosgra, Closed-loop balanced reduction with   application to a compact disc mechanism. In Selected Topics in Identification, Modeling and Control.   Vol. 9. Delft University Press, 47\u201358, 1996.\n      and\n      W. Draijer, M. Steinbuch, and  O. H. Bosgra, Adaptive control of the radial servo system of a   compact disc player. Automatica 28, 3, 455\u2013462. 1992.\n\n\n\n\n\n\nnlevp_native_fiber\n\n      The benchmark problem from the NLEVP-collection called \"fiber\", represented in the native NEP-PACK format.   One of terms in this problem is approximated by interpolation, and may not always coincide with the benchmark.   L. Kaufman, Eigenvalue problems in fiber optic design. SIAM J. Matrix Anal. Appl. 28, 1, 105\u2013117, 2006.\n      and\n      X. Huang, Z. Bai, and Y. Su, Nonlinear rank-one modification of the symmetric eigenvalue problem. J. Comput. Math. 28, 2, 218\u2013234, 2010\n\n\n\n\n\n\nExample\n\n\njulia> nep=nep_gallery(\"dep0\",100);\njulia> norm(compute_Mlincomb(nep,1.0+1.0im,ones(size(nep,1))))\n104.76153002802755\n\n\n\n\nSee also the following galleries:\n\n\n\n\nGalleryNLEVP\n\n\nGalleryWaveguide\n\n\n\n\nsource\n\n\n\n\nBerlin-Manchester collection\n\n\nIf MATLAB and the \nBerlin-Manchester collection\n are installed, we can access them with the GalleryNLEVP (which does MATLAB-access through Julia's MATLAB-package).\n\n\njulia> using GalleryNLEVP\njulia> nep=nep_gallery(NLEVP_NEP,\"hadeler\")\njulia> \u03bb,v=quasinewton(nep,\u03bb=0.2,displaylevel=1,maxit=20,tol=1e-10);\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n9.698206079849311e-11\n\n\n\n\nProblems loaded from the Berlin-Manchester collection are NEP-objects where every call to access a function generates a call to an underlying MATLAB-session. Some problems in the Berlin-Manchester collection have native support in NEP-PACK, i.e., avoiding a MATLAB-access in every call; see \nnep_gallery\n above.\n\n\n\n\nOther gallery examples\n\n\nStand-alone implementation can be accessed in a similar way, e.g., a native implementation of the Waveguide Eigenvalue Problem can be accessed as\n\n\njulia> using GalleryWaveguide\njulia> nep=nep_gallery(WEP,benchmark_problem=\"TAUSCH\");",
            "title": "NEP Gallery"
        },
        {
            "location": "/gallery/#the-gallery-function",
            "text": "A large number of examples are provided in the  nep_gallery .  julia> using Gallery\njulia> nep=nep_gallery(\"dep0\")\njulia> \u03bb,v=newton(nep)\n(-0.3587189459686265 + 0.0im, Complex{Float64}[0.284742+0.0im, -0.143316+0.0im, 0.278378+0.0im, -0.5009+0.0im, -0.613634+0.0im])\njulia> norm(compute_Mlincomb(nep,\u03bb,v))\n4.718447854656915e-16  #  NonlinearEigenproblems.Gallery.nep_gallery  \u2014  Function .   nep=nep_gallery(name)\n nep=nep_gallery(name,params)\n nep=nep_gallery(name,params;kwargs)  Collection of nonlinear eigenvalue problems. Returns a NEP object from a gallery of examples of nonlinear eigenvalue problems. The parameter  name  decides which NEP.  Supported problems:  The following list describes the NEP with a certain  name  and the associated parameters ( params ) and keyword arguments ( kwargs ), if any.   dep0    Create a random delay eiganvalue problem with one delay tau = 1.\n      One optional  params  determining the size (default = 5)  dep0_sparse \n      Create a random delay eiganvalue problem with sparse matrices and one delay tau = 1.\n      Two optional  params  determining the size (default = 5) and the fill (default = 0.25)  dep0_tridiag \n      Create a random delay eiganvalue problem with sparse tridiaognal matrices and one delay tau = 1.\n      One optional  params  determining the size (default = 100)  dep_symm_double \n      Create delay eiganvalue problem with double eigenvalues and sparse symmetric matrices and one delay tau = 1.\n      Examle from H. Voss and M. M. Betcke, Restarting iterative projection methods for Hermitian nonlinear eigenvalue problems with minmax property, Numer. Math., 2017\n      One optional  params  determining the size (default = 100)  dep_double \n      Create problem with a double non-semisimple eigenvalue in \u03bb=3\u03c0i.\n      Example from E. Jarlebring, Convergence factors of Newton methods for nonlinear eigenvalue problems, LAA, 2012  dep1 \n      A delay eigenvalue problem with one eigenvalue equal to one.  pep0 \n      Create a random polynomial eigenvalue problem.\n      One optional  params  determining the size (default = 200)  pep0_sym \n      Creates a random symmetric polynomial eigenvalue problem.\n      One optional  params  determining the size (default = 200)  pep0_sparse \n      Creates a random polynomial eigenvalue problem with sparse matrices.\n      Two optional  params  determining the size (default = 200) and the fill (default = 0.03)  real_quadratic \n      Creates a quadratic problem with real eigenvalues.\n            Four smallest eigenvalues of the problem:\n            -2051.741417993845\n            -182.101627437811\n            -39.344930222838\n            -4.039879577113  dep_distributed \n      Creates the NEP associated with example in E. Jarlebring and W. Michiels and K. Meerbergen,   The infinite Arnoldi method and an application to time-delay systems with distributed delays,   Delay Systems - Methods, Applications and New Trends, 2012.\n           Some correct eigenvalues:         -0.400236388049641 + 0.970633098237807i ,\n            -0.400236388049641 - 0.970633098237807i ,\n            2.726146249832675 + 0.000000000000000i ,\n            -1.955643591177653 + 3.364550574688863i ,\n            -1.955643591177653 - 3.364550574688863i ,\n            4.493937056300693 + 0.000000000000000i ,\n            -1.631513006819252 + 4.555484848248613i ,\n            -1.631513006819252 - 4.555484848248613i ,\n            -1.677320660400946 + 7.496870451838560i ,\n            -1.677320660400946 - 7.496870451838560i  qdep0  \n      Quadratic delay eigenvalue problem in S. W. Gaaf and E. Jarlebring, The infinite Bi-Lanczos method for   nonlinear eigenvalue problems, SIAM J. Sci. Comput., 2017  qdep1  \n      Quadratic delay eigenvalue problem in E. Jarlebring and W. Michiels and K. Meerbergen,   A linear eigenvalue algorithm for the  nonlinear eigenvalue problem, Numer. Math., 2011  qep_fixed_eig \n      A quadratic eigenvalue problem with chosen eigenvalues.\n      Two optional  params  determining the size (default = 5)   and a vector containing the eigenvalues (default = randn)  neuron0 \n      A DEP that stems from L. P. Shayer and S. A. Campbell, Stability, bifurcation and multistability   in a system of two coupled neurons with multiple time delays,   SIAM J. Applied Mathematics, 2000. It is also a benchmark example in DDE-BIFTOOL  beam \n      The DEP modelling a beam with delayed stabilizing feedback described in R. Van Beeumen, E. Jarlebring, and W. Michiels,   A rank-exploiting infinite Arnoldi algorithm for nonlinear eigenvalue problems, 2016.\n      The A1-term has rank one.\n      One optional  params  which is the size of the matrix (defalut = 100)   sine  \n      The NEP formed by the sum of a polynomial and a sine-function in \"A rank-exploiting infinite Arnoldi   algorithm for nonlinear eigenvalue problems\", R. Van Beeumen, E. Jarlebring and W. Michiels, 2016. The sine-term has rank one.  The MATLAB-package \"NLEVP: A Collection of Nonlinear Eigenvalue Problems, ACM Transactions on Mathematical Software 39(2), January 2011,   T. Betcke, N. J. Higham, V. Mehrmann, Ch. Schr\u00f6der, F. Tisseur\" provides a number of benchmark problems for NEPs.   These are available in NEP-PACK in two different ways. We have native implementations of some problems (referred to as  nlevp_native_ )   and the separate  GalleryNLEVP . The native implementation is preferred since the  GalleryNLEVP    interfaces with MATLAB and is therefore considerably slower.    nlevp_native_gun \n      The benchmark problem from the NLEVP-collection called \"gun\", represented in the native NEP-PACK format.   B.-S. Liao, Z. Bai, L.-Q. Lee, and K. Ko. Nonlinear Rayleigh-Ritz iterative method for solving large scale   nonlinear eigenvalue problems.  Taiwan. Journal of Mathematics, 14(3):869\u2013883, 2010    nlevp_native_cd_player \n      The benchmark problem from the NLEVP-collection called \"cd_player\", represented in the native NEP-PACK format.   Y. Chahlaoui, and P. M. Van Dooren, Benchmark examples for model reduction of linear time-   invariant dynamical systems. In Dimension Reduction of Large-Scale Systems, P. Benner, V. Mehrmann,   and D. C. Sorensen, Eds. Lecture Notes in Computational Science and Engineering Series, vol. 45.   Springer-Verlag, Berlin, 380\u2013392, 2005.\n      and\n      P. M. R. Wortelboer, M. Steinbuch, and  O. H. Bosgra, Closed-loop balanced reduction with   application to a compact disc mechanism. In Selected Topics in Identification, Modeling and Control.   Vol. 9. Delft University Press, 47\u201358, 1996.\n      and\n      W. Draijer, M. Steinbuch, and  O. H. Bosgra, Adaptive control of the radial servo system of a   compact disc player. Automatica 28, 3, 455\u2013462. 1992.    nlevp_native_fiber \n      The benchmark problem from the NLEVP-collection called \"fiber\", represented in the native NEP-PACK format.   One of terms in this problem is approximated by interpolation, and may not always coincide with the benchmark.   L. Kaufman, Eigenvalue problems in fiber optic design. SIAM J. Matrix Anal. Appl. 28, 1, 105\u2013117, 2006.\n      and\n      X. Huang, Z. Bai, and Y. Su, Nonlinear rank-one modification of the symmetric eigenvalue problem. J. Comput. Math. 28, 2, 218\u2013234, 2010    Example  julia> nep=nep_gallery(\"dep0\",100);\njulia> norm(compute_Mlincomb(nep,1.0+1.0im,ones(size(nep,1))))\n104.76153002802755  See also the following galleries:   GalleryNLEVP  GalleryWaveguide   source",
            "title": "The Gallery function"
        },
        {
            "location": "/gallery/#berlin-manchester-collection",
            "text": "If MATLAB and the  Berlin-Manchester collection  are installed, we can access them with the GalleryNLEVP (which does MATLAB-access through Julia's MATLAB-package).  julia> using GalleryNLEVP\njulia> nep=nep_gallery(NLEVP_NEP,\"hadeler\")\njulia> \u03bb,v=quasinewton(nep,\u03bb=0.2,displaylevel=1,maxit=20,tol=1e-10);\njulia> norm(compute_Mlincomb(nep,\u03bb,v))/norm(v)\n9.698206079849311e-11  Problems loaded from the Berlin-Manchester collection are NEP-objects where every call to access a function generates a call to an underlying MATLAB-session. Some problems in the Berlin-Manchester collection have native support in NEP-PACK, i.e., avoiding a MATLAB-access in every call; see  nep_gallery  above.",
            "title": "Berlin-Manchester collection"
        },
        {
            "location": "/gallery/#other-gallery-examples",
            "text": "Stand-alone implementation can be accessed in a similar way, e.g., a native implementation of the Waveguide Eigenvalue Problem can be accessed as  julia> using GalleryWaveguide\njulia> nep=nep_gallery(WEP,benchmark_problem=\"TAUSCH\");",
            "title": "Other gallery examples"
        },
        {
            "location": "/development/",
            "text": "Developer info\n\n\n\n\nCompiling the documentation\n\n\nCompile this documentation page by running:\n\n\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ julia --color=yes make.jl &&  mkdocs build --clean\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ firefox site/index.html\n\n\n\n\nIf you want this to appear on our documentation page \nhttps://nep-pack.github.io/NonlinearEigenproblems.jl/\n you need to push it to the \ngh-branch\n, e.g.,  by running\n\n\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ export DOCSDIR=`pwd`\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ cd /tmp\njarl@bjork:/tmp$ git clone -b \"gh-pages\" git@github.com:nep-pack/NonlinearEigenproblems.jl.git\njarl@bjork:/tmp$ cd NonlinearEigenproblems.jl\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ cp -r $DOCSDIR/site/* .\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ git add *;  git commit . -m \"refresh docs\"; git push\n\n\n\n\nMore information about \nDocumenter.jl\n: \nhere",
            "title": "Developer info"
        },
        {
            "location": "/development/#developer-info",
            "text": "",
            "title": "Developer info"
        },
        {
            "location": "/development/#compiling-the-documentation",
            "text": "Compile this documentation page by running:  jarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ julia --color=yes make.jl &&  mkdocs build --clean\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ firefox site/index.html  If you want this to appear on our documentation page  https://nep-pack.github.io/NonlinearEigenproblems.jl/  you need to push it to the  gh-branch , e.g.,  by running  jarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ export DOCSDIR=`pwd`\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ cd /tmp\njarl@bjork:/tmp$ git clone -b \"gh-pages\" git@github.com:nep-pack/NonlinearEigenproblems.jl.git\njarl@bjork:/tmp$ cd NonlinearEigenproblems.jl\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ cp -r $DOCSDIR/site/* .\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ git add *;  git commit . -m \"refresh docs\"; git push  More information about  Documenter.jl :  here",
            "title": "Compiling the documentation"
        }
    ]
}